{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用estimator 改写 mnist\n",
    "https://host02.katacoda.com/basiafusinska/courses/tensorflow-in-3-sentences/tensorflow-mnist-estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单的单层dnn网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "image_size = 28\n",
    "labels_size = 10\n",
    "hidden_size = 1024\n",
    "\n",
    "# Read in the MNIST dataset\n",
    "mnist = input_data.read_data_sets(\"/home/w/tmp/tensorflow/mnist/input_data\", one_hot=False)\n",
    "\n",
    "def input_fn(dataset):\n",
    "    features = dataset.images\n",
    "    labels = dataset.labels.astype(np.int32)\n",
    "    return features, labels\n",
    "\n",
    "# Define the Estimator\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=image_size*image_size)]\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[hidden_size],\n",
    "                                              n_classes=labels_size,\n",
    "                                              optimizer=tf.train.AdamOptimizer())\n",
    "\n",
    "# Fit the model\n",
    "features, labels = input_fn(mnist.train)\n",
    "classifier.fit(x=features, y=labels, batch_size=100, steps=1000)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "features, labels = input_fn(mnist.test)\n",
    "test_accuracy = classifier.evaluate(x=features, y=labels, steps=1)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest accuracy: %g %%\"%(test_accuracy*100))\n",
    "\n",
    "# Predict the new examples and compare with the onderlying values\n",
    "features = mnist.validation.images[:10]\n",
    "labels = mnist.validation.labels[:10].astype(np.int32)\n",
    "predictions = list(classifier.predict(x=features))\n",
    "\n",
    "print(\"\\nPredicted labels from validation set: %s\"%predictions)\n",
    "print(\"Underlying values: %s\"%list(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复杂的cnn网络\n",
    "https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/examples/tutorials/layers/cnn_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 限制显卡内存\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors \n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer \n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer \n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "  loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/w/tmp/tensorflow/mnist_convnet_model', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt-20003\n",
      "INFO:tensorflow:Saving checkpoints for 20004 into /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00036716  0.0028864   0.00004472  0.00163343  0.07248198  0.00742182\n",
      "   0.00003236  0.00626353  0.00069164  0.90817696]\n",
      " [ 0.0000009   0.00000207  0.00000021  0.00060833  0.00000797  0.99918169\n",
      "   0.00008458  0.          0.00011293  0.00000129]\n",
      " [ 0.00000206  0.00022536  0.00035146  0.00200059  0.0062197   0.00004959\n",
      "   0.00000673  0.00907924  0.01210967  0.9699555 ]\n",
      " [ 0.00053622  0.00000002  0.00003072  0.83480781  0.00000173  0.05627794\n",
      "   0.00000056  0.00004879  0.08819674  0.02009953]\n",
      " [ 0.00000153  0.99595034  0.00019687  0.00014733  0.00015516  0.00024832\n",
      "   0.00058814  0.0000241   0.00254288  0.00014534]\n",
      " [ 0.00022668  0.00008138  0.01806903  0.00002525  0.93577081  0.03319342\n",
      "   0.00888832  0.00065725  0.00234164  0.00074621]\n",
      " [ 0.00009333  0.00000923  0.00014962  0.98971128  0.00000467  0.0004517\n",
      "   0.00000012  0.00000058  0.00787937  0.00169999]\n",
      " [ 0.99960381  0.0000001   0.00002649  0.00000827  0.00000004  0.00032916\n",
      "   0.00002254  0.00000874  0.00000052  0.00000059]\n",
      " [ 0.00030898  0.96818739  0.00465062  0.00092694  0.00037667  0.00052096\n",
      "   0.00133623  0.00377351  0.0194769   0.00044165]\n",
      " [ 0.00000017  0.00017081  0.00594743  0.00086794  0.00006536  0.0000623\n",
      "   0.0000341   0.00000035  0.99284726  0.00000429]\n",
      " [ 0.00014109  0.00107128  0.00008517  0.00100404  0.00089696  0.00012153\n",
      "   0.00000069  0.98274094  0.00009983  0.01383848]\n",
      " [ 0.00000085  0.00000001  0.00008796  0.00001509  0.00000072  0.00002446\n",
      "   0.00000052  0.00000003  0.99986339  0.00000695]\n",
      " [ 0.0000004   0.00000112  0.99939859  0.00058567  0.00000014  0.00000001\n",
      "   0.00000002  0.          0.00001411  0.00000005]\n",
      " [ 0.00000196  0.00000002  0.00000905  0.          0.00009944  0.0000168\n",
      "   0.99986994  0.00000101  0.00000125  0.00000048]\n",
      " [ 0.00000344  0.00581795  0.00130421  0.00216485  0.00005638  0.0001422\n",
      "   0.00153691  0.00000104  0.98896271  0.00001033]\n",
      " [ 0.00003127  0.03681819  0.00114309  0.00127916  0.90259522  0.00233149\n",
      "   0.00545903  0.00224285  0.00358051  0.04451913]\n",
      " [ 0.00000424  0.99620467  0.00030212  0.00024171  0.00010033  0.00004019\n",
      "   0.00000666  0.0028936   0.00018446  0.00002205]\n",
      " [ 0.00000947  0.00000005  0.00000138  0.00005067  0.0014121   0.00000035\n",
      "   0.00000002  0.02708029  0.00000445  0.97144127]\n",
      " [ 0.00035284  0.00003253  0.00006727  0.00004624  0.00094841  0.00009664\n",
      "   0.99799395  0.0000004   0.00045828  0.00000362]\n",
      " [ 0.00005911  0.98734063  0.00019146  0.00010284  0.00008038  0.00040349\n",
      "   0.00081179  0.00080567  0.01011387  0.00009077]\n",
      " [ 0.00000008  0.00000292  0.00004955  0.99947888  0.00000015  0.00000676\n",
      "   0.          0.00005954  0.00001998  0.00038216]\n",
      " [ 0.00000891  0.00000487  0.00006085  0.00010923  0.00002641  0.00006991\n",
      "   0.00000062  0.99943906  0.00000346  0.00027667]\n",
      " [ 0.62251329  0.00385211  0.05590387  0.00231738  0.00299133  0.15473603\n",
      "   0.07205266  0.00007349  0.08547717  0.00008265]\n",
      " [ 0.00094487  0.00001871  0.00078863  0.00039292  0.00049257  0.00298484\n",
      "   0.00038838  0.00050695  0.99107695  0.00240526]\n",
      " [ 0.00000002  0.00000914  0.99991667  0.00006917  0.          0.00000004\n",
      "   0.          0.00000012  0.00000483  0.        ]\n",
      " [ 0.00001414  0.99771106  0.00006065  0.00005544  0.00000857  0.00006134\n",
      "   0.00000643  0.00138852  0.00067553  0.00001821]\n",
      " [ 0.00000002  0.0000003   0.00000345  0.0008808   0.00000002  0.00000003\n",
      "   0.          0.99906379  0.00000019  0.00005138]\n",
      " [ 0.0001469   0.00484168  0.98579651  0.00248833  0.00454569  0.00003106\n",
      "   0.00046968  0.00001636  0.00161315  0.00005073]\n",
      " [ 0.91511357  0.00014127  0.00541509  0.00121085  0.00093929  0.01411694\n",
      "   0.01120376  0.00211897  0.01733818  0.03240198]\n",
      " [ 0.00019559  0.00006831  0.00034238  0.0000159   0.00016617  0.00032816\n",
      "   0.99880564  0.00000058  0.00007687  0.00000039]\n",
      " [ 0.0000375   0.00063741  0.00008136  0.00543559  0.00766409  0.89256299\n",
      "   0.00341675  0.00007936  0.0810446   0.00904018]\n",
      " [ 0.04951698  0.00000006  0.00688117  0.00008431  0.00021081  0.00157206\n",
      "   0.00234019  0.0000006   0.93900084  0.00039304]\n",
      " [ 0.00001485  0.00000644  0.00003571  0.99810141  0.00000051  0.00180276\n",
      "   0.00000613  0.00000267  0.00000046  0.00002912]\n",
      " [ 0.00000707  0.00000128  0.99692023  0.00265831  0.00017745  0.00001849\n",
      "   0.0000014   0.00001993  0.00016762  0.0000283 ]\n",
      " [ 0.0000063   0.02232915  0.97273761  0.0033822   0.00000699  0.00009643\n",
      "   0.00049963  0.00002682  0.00091456  0.00000038]\n",
      " [ 0.01182159  0.00413415  0.0560196   0.00152788  0.18000235  0.01279792\n",
      "   0.72361505  0.00123637  0.00463569  0.00420941]\n",
      " [ 0.00016546  0.00956734  0.00088505  0.97341067  0.0000769   0.01068434\n",
      "   0.00001024  0.00017275  0.00099783  0.00402932]\n",
      " [ 0.00000007  0.00003412  0.00518443  0.03015647  0.00000109  0.00000058\n",
      "   0.          0.96418518  0.00002963  0.00040834]\n",
      " [ 0.00000042  0.00019606  0.00008591  0.00167212  0.00000035  0.00000005\n",
      "   0.          0.99752003  0.00000239  0.00052262]\n",
      " [ 0.00663219  0.00001265  0.56274778  0.00398488  0.00006822  0.00128894\n",
      "   0.00115321  0.42350546  0.00008829  0.00051836]\n",
      " [ 0.00006728  0.0000021   0.00001126  0.00001237  0.00307309  0.00003228\n",
      "   0.00000376  0.02345597  0.00007521  0.97326672]\n",
      " [ 0.00000836  0.00083943  0.00006027  0.09875013  0.79266161  0.00001977\n",
      "   0.00000129  0.04286081  0.00437816  0.06042014]\n",
      " [ 0.00371174  0.00007924  0.00293387  0.00006789  0.96220863  0.0045195\n",
      "   0.00150818  0.00134717  0.00100622  0.02261755]\n",
      " [ 0.00000001  0.00000001  0.00033726  0.00010728  0.0000092   0.          0.\n",
      "   0.99953175  0.00000022  0.00001429]\n",
      " [ 0.00000183  0.00000006  0.00000273  0.00000011  0.00039658  0.00079738\n",
      "   0.99879104  0.          0.00001009  0.00000008]\n",
      " [ 0.00001698  0.99791974  0.00067556  0.00012252  0.0000892   0.00001713\n",
      "   0.00058384  0.00019326  0.00036956  0.00001196]\n",
      " [ 0.99937087  0.          0.00000015  0.00000001  0.00000001  0.00059954\n",
      "   0.00002712  0.00000001  0.00000231  0.00000007]\n",
      " [ 0.00011264  0.00001321  0.00000664  0.00048523  0.04394716  0.00040569\n",
      "   0.00000652  0.25897294  0.00042849  0.69562143]\n",
      " [ 0.00021318  0.98659617  0.00169909  0.0020102   0.00032782  0.00018582\n",
      "   0.0025702   0.0004493   0.00578747  0.00016074]\n",
      " [ 0.00007704  0.9682008   0.00217738  0.00614367  0.00357207  0.00218788\n",
      "   0.00427085  0.00116976  0.01143542  0.00076506]\n",
      " [ 0.0000006   0.0000003   0.0000157   0.00000001  0.00052706  0.00019716\n",
      "   0.99924552  0.00000018  0.0000134   0.0000001 ]\n",
      " [ 0.00000022  0.          0.0001441   0.00021329  0.00000001  0.000001    0.\n",
      "   0.99962616  0.0000012   0.00001403]\n",
      " [ 0.00035568  0.0002602   0.98140746  0.00383594  0.00014497  0.00013719\n",
      "   0.00012438  0.0131651   0.00026766  0.00030139]\n",
      " [ 0.78697681  0.00000002  0.00002808  0.00020553  0.0000147   0.00052831\n",
      "   0.00014841  0.00109628  0.01486565  0.19613619]\n",
      " [ 0.00000148  0.00009027  0.00014348  0.0009235   0.98559004  0.00044156\n",
      "   0.00018385  0.00142408  0.00034778  0.010854  ]\n",
      " [ 0.00027368  0.00000086  0.00000078  0.00058591  0.0002005   0.00011922\n",
      "   0.00000003  0.96799177  0.00000935  0.03081792]\n",
      " [ 0.99988174  0.          0.00000202  0.00000001  0.          0.00009841\n",
      "   0.0000176   0.          0.00000013  0.00000005]\n",
      " [ 0.00968917  0.02209992  0.14948027  0.03399395  0.00004985  0.00042385\n",
      "   0.00062012  0.00086532  0.78169703  0.00108062]\n",
      " [ 0.00006553  0.0000056   0.00006525  0.00000944  0.00067532  0.00985698\n",
      "   0.9891265   0.00000005  0.00019167  0.00000362]\n",
      " [ 0.00000001  0.00000018  0.00016336  0.00039184  0.00000147  0.00008754\n",
      "   0.00002133  0.00000033  0.9993338   0.00000008]\n",
      " [ 0.00000236  0.00001444  0.00000953  0.00016096  0.00275965  0.00002653\n",
      "   0.00000004  0.05271512  0.00018798  0.94412339]\n",
      " [ 0.99988186  0.          0.0000004   0.0000001   0.00000016  0.00010774\n",
      "   0.00000771  0.00000011  0.00000091  0.00000099]\n",
      " [ 0.00359014  0.0005728   0.02044342  0.00033376  0.00520837  0.00476401\n",
      "   0.96450317  0.00001898  0.0005623   0.00000301]\n",
      " [ 0.00000359  0.00000018  0.00001417  0.00001239  0.0000144   0.00001056\n",
      "   0.00000003  0.99936658  0.00003797  0.00054021]\n",
      " [ 0.01325112  0.0023785   0.03686409  0.00017201  0.04384856  0.00102223\n",
      "   0.89997852  0.00019316  0.00186486  0.00042701]\n",
      " [ 0.00000334  0.0000332   0.0009067   0.0007972   0.00011143  0.00004265\n",
      "   0.00002917  0.00000009  0.99807066  0.0000056 ]\n",
      " [ 0.00200964  0.00324193  0.00294703  0.00022226  0.69159263  0.0010566\n",
      "   0.00954631  0.01530616  0.07214746  0.20192996]\n",
      " [ 0.00000435  0.9977659   0.00004337  0.00000842  0.00001828  0.00000678\n",
      "   0.00033736  0.00001155  0.0017953   0.00000856]\n",
      " [ 0.01020178  0.00000001  0.00000036  0.00005212  0.00011991  0.00255654\n",
      "   0.00000025  0.98030454  0.00000083  0.00676367]\n",
      " [ 0.00031159  0.0000001   0.00004337  0.00000272  0.03606794  0.00242162\n",
      "   0.00181438  0.00017082  0.00354624  0.95562118]\n",
      " [ 0.00000848  0.00285885  0.99616063  0.00018906  0.00011003  0.00000042\n",
      "   0.00049576  0.00003666  0.00013946  0.0000005 ]\n",
      " [ 0.00168348  0.0000679   0.00322128  0.00004681  0.956357    0.00101723\n",
      "   0.00524526  0.00620859  0.004388    0.02176445]\n",
      " [ 0.0000001   0.00000049  0.00002133  0.00000654  0.9996112   0.00000772\n",
      "   0.00000111  0.00000161  0.00000438  0.00034541]\n",
      " [ 0.00020424  0.00014548  0.03129521  0.0159749   0.00000819  0.00003656\n",
      "   0.00000104  0.94214261  0.00011792  0.01007389]\n",
      " [ 0.00000019  0.00000002  0.00000016  0.0000001   0.99966717  0.00000176\n",
      "   0.00000435  0.00000905  0.00001025  0.00030697]\n",
      " [ 0.00001285  0.00000091  0.00000674  0.00046309  0.00000001  0.99920565\n",
      "   0.00003068  0.00000003  0.00027977  0.00000028]\n",
      " [ 0.00000014  0.00000188  0.99987328  0.00012101  0.00000003  0.00000019\n",
      "   0.00000004  0.00000074  0.00000273  0.00000002]\n",
      " [ 0.00855016  0.00002199  0.96893322  0.02143487  0.00001215  0.00001332\n",
      "   0.00001336  0.00001333  0.00098319  0.00002446]\n",
      " [ 0.00013948  0.00369028  0.00086845  0.00063233  0.00000389  0.00000935\n",
      "   0.0000001   0.98576432  0.00030308  0.00858869]\n",
      " [ 0.00009076  0.01286504  0.9746334   0.00999315  0.00000563  0.00002002\n",
      "   0.00018374  0.00003997  0.00216468  0.00000381]\n",
      " [ 0.00001859  0.99848217  0.00013104  0.00005949  0.00006734  0.00000142\n",
      "   0.00001463  0.0003865   0.00082852  0.00001025]\n",
      " [ 0.00000937  0.12392883  0.25827682  0.27487484  0.00000456  0.00001967\n",
      "   0.00000027  0.00355824  0.33928356  0.00004383]\n",
      " [ 0.00000008  0.00000012  0.99999297  0.00000663  0.          0.          0.\n",
      "   0.          0.00000013  0.        ]\n",
      " [ 0.00000277  0.00000034  0.00007447  0.00000006  0.000001    0.00002358\n",
      "   0.99754745  0.          0.00235027  0.00000001]\n",
      " [ 0.00005875  0.00004639  0.00003022  0.0010749   0.02828464  0.00112465\n",
      "   0.00002757  0.05550646  0.0001673   0.91367918]\n",
      " [ 0.00000433  0.9968766   0.00004076  0.00054078  0.00010987  0.00000444\n",
      "   0.00001321  0.00146489  0.000876    0.0000692 ]\n",
      " [ 0.00002855  0.00000253  0.00007692  0.00000464  0.99755621  0.00032278\n",
      "   0.00049982  0.00009994  0.00031696  0.00109182]\n",
      " [ 0.00000153  0.0000018   0.00000526  0.00169767  0.00000016  0.99648452\n",
      "   0.0000022   0.00000041  0.00177956  0.00002685]\n",
      " [ 0.00009973  0.00036446  0.00047831  0.00163366  0.00000431  0.0000062\n",
      "   0.00000009  0.99422884  0.00025041  0.00293395]\n",
      " [ 0.0000965   0.00013126  0.00005725  0.0009378   0.01144588  0.00082149\n",
      "   0.00438539  0.00000461  0.97871804  0.00340183]\n",
      " [ 0.19070995  0.00056509  0.01247437  0.00132985  0.0083398   0.03418665\n",
      "   0.7347908   0.00019249  0.0124845   0.00492649]\n",
      " [ 0.00000252  0.0000045   0.99537539  0.00199068  0.0000001   0.00000026\n",
      "   0.          0.0025141   0.00010914  0.00000325]\n",
      " [ 0.00001046  0.00000004  0.00000002  0.00000033  0.00002212  0.00000445\n",
      "   0.00000001  0.99971539  0.00000003  0.00024712]\n",
      " [ 0.00003588  0.00000491  0.00000903  0.00001402  0.99458486  0.00060784\n",
      "   0.00007935  0.00010688  0.00028817  0.00426918]\n",
      " [ 0.00216206  0.00715183  0.02074003  0.16882619  0.00064983  0.00628238\n",
      "   0.0002587   0.00001864  0.79293668  0.00097372]\n",
      " [ 0.00000185  0.00000134  0.99785334  0.0015972   0.00002041  0.000001\n",
      "   0.00000049  0.00000001  0.000519    0.00000537]\n",
      " [ 0.00015078  0.00000135  0.00001639  0.92796648  0.00000077  0.07106031\n",
      "   0.00000016  0.00002084  0.00000597  0.00077717]\n",
      " [ 0.00000001  0.00184726  0.00004916  0.00809909  0.01024165  0.00022587\n",
      "   0.00000014  0.90010142  0.00025527  0.07918015]\n",
      " [ 0.00004525  0.99432969  0.00028967  0.00042786  0.00008467  0.00015271\n",
      "   0.00024664  0.00006931  0.00425908  0.00009511]\n",
      " [ 0.00000484  0.0000002   0.00004267  0.00000004  0.00069826  0.0000088\n",
      "   0.99924242  0.00000019  0.0000022   0.00000031]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.147521, step = 20004\n",
      "INFO:tensorflow:global_step/sec: 179.261\n",
      "INFO:tensorflow:loss = 0.168858, step = 20104 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.871\n",
      "INFO:tensorflow:loss = 0.0711041, step = 20204 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.086\n",
      "INFO:tensorflow:loss = 0.227588, step = 20304 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.369\n",
      "INFO:tensorflow:loss = 0.221463, step = 20404 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.86\n",
      "INFO:tensorflow:loss = 0.123198, step = 20504 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.651\n",
      "INFO:tensorflow:loss = 0.228068, step = 20604 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.805\n",
      "INFO:tensorflow:loss = 0.0868666, step = 20704 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.139\n",
      "INFO:tensorflow:loss = 0.0766645, step = 20804 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.26\n",
      "INFO:tensorflow:loss = 0.22642, step = 20904 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.824\n",
      "INFO:tensorflow:loss = 0.10064, step = 21004 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.364\n",
      "INFO:tensorflow:loss = 0.173867, step = 21104 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.901\n",
      "INFO:tensorflow:loss = 0.107871, step = 21204 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.231\n",
      "INFO:tensorflow:loss = 0.115618, step = 21304 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.21\n",
      "INFO:tensorflow:loss = 0.136687, step = 21404 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.613\n",
      "INFO:tensorflow:loss = 0.0813435, step = 21504 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.369\n",
      "INFO:tensorflow:loss = 0.0873787, step = 21604 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.44\n",
      "INFO:tensorflow:loss = 0.0542916, step = 21704 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.701\n",
      "INFO:tensorflow:loss = 0.138541, step = 21804 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.053\n",
      "INFO:tensorflow:loss = 0.10794, step = 21904 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.609\n",
      "INFO:tensorflow:loss = 0.0755985, step = 22004 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.273\n",
      "INFO:tensorflow:loss = 0.0917012, step = 22104 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.633\n",
      "INFO:tensorflow:loss = 0.0579008, step = 22204 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.655\n",
      "INFO:tensorflow:loss = 0.0682085, step = 22304 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.109\n",
      "INFO:tensorflow:loss = 0.151798, step = 22404 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.157\n",
      "INFO:tensorflow:loss = 0.124122, step = 22504 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.943\n",
      "INFO:tensorflow:loss = 0.123241, step = 22604 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.986\n",
      "INFO:tensorflow:loss = 0.14176, step = 22704 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.328\n",
      "INFO:tensorflow:loss = 0.148653, step = 22804 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.562\n",
      "INFO:tensorflow:loss = 0.0541132, step = 22904 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.814\n",
      "INFO:tensorflow:loss = 0.157161, step = 23004 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.803\n",
      "INFO:tensorflow:loss = 0.0575396, step = 23104 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.215\n",
      "INFO:tensorflow:loss = 0.122858, step = 23204 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.061\n",
      "INFO:tensorflow:loss = 0.0936465, step = 23304 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.522\n",
      "INFO:tensorflow:loss = 0.114921, step = 23404 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.881\n",
      "INFO:tensorflow:loss = 0.165188, step = 23504 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.454\n",
      "INFO:tensorflow:loss = 0.0658704, step = 23604 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.383\n",
      "INFO:tensorflow:loss = 0.0944275, step = 23704 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.145\n",
      "INFO:tensorflow:loss = 0.124089, step = 23804 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.568\n",
      "INFO:tensorflow:loss = 0.0827167, step = 23904 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.238\n",
      "INFO:tensorflow:loss = 0.0904969, step = 24004 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.142\n",
      "INFO:tensorflow:loss = 0.0890894, step = 24104 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.975\n",
      "INFO:tensorflow:loss = 0.0779406, step = 24204 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.369\n",
      "INFO:tensorflow:loss = 0.123285, step = 24304 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.189\n",
      "INFO:tensorflow:loss = 0.154881, step = 24404 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.398\n",
      "INFO:tensorflow:loss = 0.125388, step = 24504 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.64\n",
      "INFO:tensorflow:loss = 0.20934, step = 24604 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.885\n",
      "INFO:tensorflow:loss = 0.0919091, step = 24704 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.929\n",
      "INFO:tensorflow:loss = 0.104996, step = 24804 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.423\n",
      "INFO:tensorflow:loss = 0.150177, step = 24904 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.67\n",
      "INFO:tensorflow:probabilities = [[ 0.02680191  0.00009744  0.00307255  0.00044949  0.00179123  0.00163339\n",
      "   0.00126211  0.00106811  0.92094457  0.04287924]\n",
      " [ 0.00000001  0.00000001  0.00000026  0.00000101  0.99587005  0.00001698\n",
      "   0.00000748  0.00042378  0.0000029   0.00367753]\n",
      " [ 0.00008144  0.00104452  0.98829633  0.00067355  0.00000234  0.00029279\n",
      "   0.00002243  0.0001267   0.00941189  0.00004803]\n",
      " [ 0.          0.00000019  0.00061501  0.99815971  0.00000001  0.00001929\n",
      "   0.          0.00000063  0.00119772  0.00000752]\n",
      " [ 0.00038822  0.00008303  0.99854916  0.00044168  0.00000002  0.00020631\n",
      "   0.00000082  0.000129    0.00020039  0.00000146]\n",
      " [ 0.99985826  0.00000002  0.00003599  0.00000272  0.00000017  0.00000231\n",
      "   0.00008052  0.00000553  0.00000106  0.00001349]\n",
      " [ 0.0000424   0.98901051  0.00068334  0.00014523  0.00037852  0.0000856\n",
      "   0.00018875  0.00129746  0.00807727  0.00009076]\n",
      " [ 0.00000345  0.99659133  0.00018606  0.00006972  0.00027059  0.00000242\n",
      "   0.00031558  0.00031902  0.00222883  0.00001313]\n",
      " [ 0.00000065  0.          0.00001842  0.00007304  0.00000046  0.00002603\n",
      "   0.00000002  0.00000074  0.99959666  0.00028392]\n",
      " [ 0.01123985  0.0009066   0.56582373  0.02074025  0.39486906  0.00010476\n",
      "   0.00007005  0.00006051  0.00018085  0.00600433]\n",
      " [ 0.0002355   0.00006408  0.00013695  0.00004821  0.00047144  0.00545285\n",
      "   0.9935661   0.          0.0000247   0.00000008]\n",
      " [ 0.00276819  0.00000004  0.00000262  0.00000074  0.00009329  0.00002073\n",
      "   0.0000009   0.95705152  0.00000063  0.04006137]\n",
      " [ 0.00759077  0.00008917  0.00044181  0.00013967  0.00105493  0.00399424\n",
      "   0.98508102  0.00001064  0.00143946  0.00015826]\n",
      " [ 0.99995351  0.00000013  0.0000074   0.00000038  0.00000003  0.00000858\n",
      "   0.00000504  0.00000039  0.00000198  0.00002262]\n",
      " [ 0.00000662  0.00002375  0.00014995  0.00000952  0.00003015  0.00004087\n",
      "   0.99968994  0.          0.00004917  0.00000005]\n",
      " [ 0.00000286  0.99395657  0.00012415  0.0003464   0.00000665  0.00000166\n",
      "   0.00006388  0.00002117  0.005455    0.00002168]\n",
      " [ 0.05164241  0.00022392  0.00181859  0.01757067  0.0056636   0.00703735\n",
      "   0.00031085  0.21942943  0.00617851  0.69012469]\n",
      " [ 0.99505532  0.00000998  0.00029074  0.00000801  0.00000594  0.00072351\n",
      "   0.00377922  0.0000036   0.00007664  0.00004704]\n",
      " [ 0.00000003  0.00020164  0.00027266  0.99331796  0.00002188  0.00069786\n",
      "   0.          0.00000894  0.00466143  0.00081765]\n",
      " [ 0.00028442  0.00047412  0.00769036  0.0044464   0.07346284  0.01200344\n",
      "   0.00008411  0.04362168  0.0012326   0.85670006]\n",
      " [ 0.00006015  0.00001432  0.00009792  0.00426172  0.00000221  0.00004388\n",
      "   0.00000006  0.98606992  0.00000762  0.00944224]\n",
      " [ 0.00002314  0.00024813  0.00001274  0.99850792  0.00000158  0.00106145\n",
      "   0.00000253  0.00000137  0.00009934  0.00004182]\n",
      " [ 0.00001687  0.00002712  0.00000705  0.00005564  0.00619357  0.00002048\n",
      "   0.00000175  0.00567497  0.00002461  0.98797786]\n",
      " [ 0.00001007  0.00001992  0.00003522  0.01102599  0.00007466  0.96834004\n",
      "   0.00331591  0.00000031  0.01708264  0.00009517]\n",
      " [ 0.00000088  0.0004506   0.00001151  0.00347682  0.9674384   0.00007538\n",
      "   0.00000768  0.0031781   0.00371467  0.02164589]\n",
      " [ 0.00021472  0.00032406  0.00009501  0.0006022   0.00001242  0.99605227\n",
      "   0.0009106   0.00017701  0.00160978  0.00000185]\n",
      " [ 0.00028202  0.00737224  0.00775272  0.05247837  0.00513893  0.04254454\n",
      "   0.00052138  0.58789343  0.29108921  0.00492719]\n",
      " [ 0.0000058   0.00000017  0.00048537  0.00012593  0.00000039  0.00000046\n",
      "   0.          0.99838185  0.00000409  0.0009959 ]\n",
      " [ 0.00000321  0.00000075  0.00000699  0.00002159  0.00000005  0.00009145\n",
      "   0.00000053  0.00000259  0.99986887  0.00000398]\n",
      " [ 0.00000316  0.00001162  0.00002127  0.98998427  0.00000254  0.0097882\n",
      "   0.00000017  0.00000341  0.00015019  0.00003516]\n",
      " [ 0.00000001  0.00002363  0.00020544  0.00050783  0.00000013  0.0000002\n",
      "   0.          0.97530192  0.0000136   0.02394725]\n",
      " [ 0.00072138  0.0000007   0.00084384  0.00056016  0.00005164  0.00018\n",
      "   0.0003523   0.00000006  0.99725169  0.00003817]\n",
      " [ 0.00000005  0.00010234  0.99915707  0.00070529  0.00000923  0.00000024\n",
      "   0.00001021  0.00000019  0.00001538  0.00000004]\n",
      " [ 0.00021559  0.00073981  0.00527607  0.00684009  0.0000384   0.00004543\n",
      "   0.00000023  0.98347038  0.00007132  0.00330277]\n",
      " [ 0.          0.00000003  0.00000133  0.00000969  0.          0.          0.\n",
      "   0.99997032  0.00000001  0.00001859]\n",
      " [ 0.0001924   0.00006184  0.00085186  0.00282332  0.00003398  0.00623235\n",
      "   0.00038019  0.00000029  0.98924875  0.00017498]\n",
      " [ 0.00075552  0.00003874  0.00148732  0.000109    0.00006625  0.00229438\n",
      "   0.99456751  0.00000204  0.00066491  0.0000144 ]\n",
      " [ 0.00415736  0.0000257   0.00313795  0.00016263  0.00150241  0.00194602\n",
      "   0.98894417  0.00004064  0.00004423  0.00003887]\n",
      " [ 0.00000812  0.00098246  0.00027365  0.01696953  0.801521    0.0003856\n",
      "   0.00007408  0.05189713  0.04578941  0.08209905]\n",
      " [ 0.00000563  0.0000021   0.00016454  0.99667943  0.00000109  0.00137141\n",
      "   0.00000676  0.00000003  0.00170955  0.00005937]\n",
      " [ 0.00001626  0.99576026  0.00047778  0.00024036  0.00005401  0.00061737\n",
      "   0.00018326  0.00005335  0.00250697  0.00009039]\n",
      " [ 0.00000015  0.00000241  0.00306952  0.00827977  0.000001    0.00000031\n",
      "   0.00000001  0.98859239  0.00000217  0.0000523 ]\n",
      " [ 0.0000694   0.00000086  0.00014447  0.98040879  0.00013939  0.00126146\n",
      "   0.00000046  0.00001988  0.00042282  0.01753244]\n",
      " [ 0.00003452  0.00000019  0.0000005   0.00000233  0.00027161  0.99588603\n",
      "   0.00371037  0.00000003  0.00008923  0.00000525]\n",
      " [ 0.00000745  0.99780923  0.00003132  0.00023862  0.00040052  0.00000183\n",
      "   0.00001463  0.00003536  0.00141158  0.00004959]\n",
      " [ 0.00037511  0.00000494  0.0000016   0.00443814  0.00000702  0.99284184\n",
      "   0.00000164  0.00007907  0.00018075  0.00206998]\n",
      " [ 0.00001274  0.00000005  0.99969304  0.00027971  0.00000092  0.00000014\n",
      "   0.00000186  0.00000478  0.00000678  0.00000002]\n",
      " [ 0.00096192  0.00001591  0.02691902  0.00000939  0.95700061  0.00430353\n",
      "   0.00625739  0.00159354  0.00122312  0.00171562]\n",
      " [ 0.0000153   0.00059325  0.00000046  0.00261149  0.00037393  0.00021918\n",
      "   0.00000055  0.00191421  0.01318872  0.98108292]\n",
      " [ 0.98932868  0.00007085  0.00065093  0.00017908  0.00000591  0.00035204\n",
      "   0.00000528  0.00795315  0.0000108   0.00144332]\n",
      " [ 0.          0.00000024  0.00000007  0.00000159  0.99951506  0.00000744\n",
      "   0.00000014  0.0000012   0.00002517  0.00044925]\n",
      " [ 0.00006772  0.00015363  0.99121827  0.00539459  0.00040164  0.00002864\n",
      "   0.00001837  0.00002565  0.00117997  0.00151164]\n",
      " [ 0.00000225  0.00000592  0.00001845  0.00000109  0.00027375  0.00029192\n",
      "   0.99880719  0.00000004  0.00059905  0.00000032]\n",
      " [ 0.00006907  0.00006627  0.00067039  0.97452265  0.00000206  0.01405372\n",
      "   0.00000571  0.0000017   0.01051436  0.00009401]\n",
      " [ 0.00000038  0.00000024  0.00000077  0.00002418  0.034418    0.00045737\n",
      "   0.00000723  0.00035336  0.00002812  0.96471035]\n",
      " [ 0.00001064  0.9956677   0.000365    0.00102729  0.00042622  0.0000538\n",
      "   0.00009572  0.00064835  0.0011277   0.00057763]\n",
      " [ 0.00000028  0.99879009  0.00002017  0.00057803  0.0000266   0.00000182\n",
      "   0.00000023  0.00008018  0.00028298  0.00021976]\n",
      " [ 0.00000085  0.00001461  0.00000083  0.9971711   0.00000006  0.00280296\n",
      "   0.00000003  0.00000001  0.00000088  0.00000868]\n",
      " [ 0.0000204   0.99901688  0.00024356  0.00001932  0.00002224  0.00000705\n",
      "   0.0000764   0.000043    0.00053093  0.00002022]\n",
      " [ 0.00042176  0.0000368   0.98936558  0.00438339  0.00069384  0.00004633\n",
      "   0.00002072  0.00013248  0.00400283  0.00089625]\n",
      " [ 0.00141434  0.00060983  0.75806701  0.028944    0.00071804  0.00178\n",
      "   0.00051037  0.00049023  0.19946431  0.00800188]\n",
      " [ 0.00000036  0.00000342  0.00000789  0.99881387  0.0000006   0.00098217\n",
      "   0.00000001  0.00003359  0.00000771  0.00015035]\n",
      " [ 0.00000009  0.00000013  0.00000002  0.00000922  0.00160391  0.00000072\n",
      "   0.00000003  0.00038487  0.00000024  0.9980008 ]\n",
      " [ 0.00000009  0.00000297  0.00002744  0.00078877  0.00000031  0.00004246\n",
      "   0.00000009  0.00000093  0.99913651  0.00000053]\n",
      " [ 0.0001339   0.00003752  0.00537621  0.98805797  0.00000078  0.00015429\n",
      "   0.00000221  0.00000096  0.00608989  0.00014623]\n",
      " [ 0.00000042  0.00000088  0.0000454   0.00081525  0.00001583  0.00002993\n",
      "   0.00000035  0.00000134  0.99905413  0.00003642]\n",
      " [ 0.00001151  0.99917763  0.00027699  0.00002717  0.00000411  0.00000888\n",
      "   0.0000815   0.00003508  0.00036461  0.00001244]\n",
      " [ 0.27204478  0.00019159  0.00017513  0.00011652  0.00174843  0.00750045\n",
      "   0.00023167  0.71363437  0.00022612  0.00413091]\n",
      " [ 0.00000007  0.00001862  0.98590231  0.01325615  0.00000004  0.00000002\n",
      "   0.00000001  0.          0.00082285  0.        ]\n",
      " [ 0.00000046  0.00009689  0.00032856  0.9991948   0.00000285  0.00016837\n",
      "   0.00000501  0.          0.00020064  0.00000241]\n",
      " [ 0.00010583  0.00001704  0.00050222  0.00002973  0.0000252   0.00045663\n",
      "   0.00026029  0.00000265  0.99852991  0.00007048]\n",
      " [ 0.00000006  0.0000844   0.00007036  0.99676478  0.00000035  0.00289605\n",
      "   0.00000733  0.0000065   0.00015472  0.00001536]\n",
      " [ 0.00006526  0.98969519  0.00057803  0.00081661  0.00021847  0.00007068\n",
      "   0.00086239  0.00545318  0.00206976  0.0001704 ]\n",
      " [ 0.00000004  0.00004072  0.00015449  0.00000434  0.00019845  0.00001693\n",
      "   0.9994905   0.00000006  0.00009436  0.00000006]\n",
      " [ 0.0000002   0.00021899  0.00001394  0.00014781  0.98776162  0.00221583\n",
      "   0.0000082   0.00006146  0.00134267  0.00822922]\n",
      " [ 0.00000002  0.00000001  0.00000015  0.99997139  0.00000003  0.00002387\n",
      "   0.          0.          0.0000034   0.00000111]\n",
      " [ 0.00457625  0.00000003  0.00000287  0.00000066  0.00077447  0.00001087\n",
      "   0.00000036  0.99278063  0.00000081  0.00185298]\n",
      " [ 0.00001346  0.00000296  0.00337967  0.9886874   0.0000001   0.00488956\n",
      "   0.00006207  0.00000031  0.00296404  0.00000036]\n",
      " [ 0.00000374  0.00000127  0.00040471  0.07211974  0.00000921  0.00069707\n",
      "   0.00000135  0.00000469  0.92673433  0.000024  ]\n",
      " [ 0.00110754  0.00319237  0.97030008  0.01461375  0.00000994  0.00030658\n",
      "   0.00002272  0.00010329  0.01032486  0.00001893]\n",
      " [ 0.00001237  0.00000225  0.00262953  0.00000791  0.00002941  0.00535203\n",
      "   0.99102461  0.0000001   0.00093977  0.000002  ]\n",
      " [ 0.9948107   0.00003297  0.00453263  0.00008275  0.00000143  0.00015512\n",
      "   0.00021812  0.0000244   0.00000066  0.00014108]\n",
      " [ 0.99998903  0.          0.00000041  0.00000001  0.          0.00000301\n",
      "   0.00000673  0.          0.00000064  0.00000033]\n",
      " [ 0.00017735  0.02929288  0.9660455   0.00326286  0.00000201  0.00013074\n",
      "   0.00088644  0.00000329  0.00019647  0.00000254]\n",
      " [ 0.00000003  0.01119847  0.98381454  0.00456317  0.          0.00000005\n",
      "   0.00000001  0.00000003  0.00042391  0.        ]\n",
      " [ 0.00000098  0.00000002  0.00000001  0.00001864  0.00000057  0.99989009\n",
      "   0.00000178  0.00000032  0.00008725  0.00000028]\n",
      " [ 0.00040607  0.0000032   0.99718189  0.00184498  0.0000114   0.00032511\n",
      "   0.0001578   0.00000253  0.00006642  0.00000063]\n",
      " [ 0.00007415  0.00001517  0.01110433  0.00330884  0.00000475  0.00000189\n",
      "   0.0000003   0.98467678  0.00000743  0.00080643]\n",
      " [ 0.00000173  0.00000073  0.00000027  0.00000054  0.99411362  0.00000159\n",
      "   0.00000362  0.00175077  0.00003962  0.00408752]\n",
      " [ 0.00001408  0.98965937  0.00151498  0.001215    0.00084772  0.00048615\n",
      "   0.00047532  0.00012115  0.00553803  0.0001282 ]\n",
      " [ 0.00000281  0.00000077  0.01366986  0.00143951  0.00000038  0.00000166\n",
      "   0.          0.00002688  0.98475826  0.00009995]\n",
      " [ 0.00005262  0.00000062  0.00003961  0.0017932   0.00001326  0.00603345\n",
      "   0.00005925  0.00000007  0.99183744  0.00017044]\n",
      " [ 0.99985945  0.          0.00005643  0.00000006  0.0000007   0.00000262\n",
      "   0.00002329  0.00000801  0.00000269  0.00004687]\n",
      " [ 0.99999547  0.          0.00000362  0.          0.          0.00000084\n",
      "   0.00000006  0.          0.          0.        ]\n",
      " [ 0.99754459  0.00002632  0.00077133  0.00031626  0.00005933  0.00029825\n",
      "   0.00053876  0.00004128  0.0000615   0.00034246]\n",
      " [ 0.00000219  0.00000011  0.00000738  0.00000083  0.9978897   0.00000228\n",
      "   0.00011438  0.00004362  0.00002261  0.00191685]\n",
      " [ 0.00000203  0.00000077  0.00051058  0.99296713  0.00000037  0.00098159\n",
      "   0.00000003  0.00000029  0.00552391  0.00001349]\n",
      " [ 0.99978012  0.00000006  0.00004785  0.00003552  0.          0.00006447\n",
      "   0.00000056  0.00000827  0.00000008  0.0000631 ]\n",
      " [ 0.00022351  0.00000146  0.00084097  0.00000006  0.00676488  0.0000259\n",
      "   0.9919138   0.00002661  0.00006205  0.00014066]\n",
      " [ 0.00000721  0.00007368  0.00002283  0.00014669  0.00865948  0.00021096\n",
      "   0.00001297  0.00049035  0.00007301  0.99030286]] (23.403 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0964704, step = 25004 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.764\n",
      "INFO:tensorflow:loss = 0.0590065, step = 25104 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.147\n",
      "INFO:tensorflow:loss = 0.0750521, step = 25204 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.558\n",
      "INFO:tensorflow:loss = 0.0896906, step = 25304 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.64\n",
      "INFO:tensorflow:loss = 0.187506, step = 25404 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.762\n",
      "INFO:tensorflow:loss = 0.178361, step = 25504 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.542\n",
      "INFO:tensorflow:loss = 0.0760943, step = 25604 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 217\n",
      "INFO:tensorflow:loss = 0.0846064, step = 25704 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.736\n",
      "INFO:tensorflow:loss = 0.160039, step = 25804 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 217\n",
      "INFO:tensorflow:loss = 0.211431, step = 25904 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.311\n",
      "INFO:tensorflow:loss = 0.150886, step = 26004 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.72\n",
      "INFO:tensorflow:loss = 0.162047, step = 26104 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.559\n",
      "INFO:tensorflow:loss = 0.0694358, step = 26204 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.007\n",
      "INFO:tensorflow:loss = 0.0689022, step = 26304 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.563\n",
      "INFO:tensorflow:loss = 0.223018, step = 26404 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.607\n",
      "INFO:tensorflow:loss = 0.071739, step = 26504 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.451\n",
      "INFO:tensorflow:loss = 0.194949, step = 26604 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.499\n",
      "INFO:tensorflow:loss = 0.0434381, step = 26704 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.109\n",
      "INFO:tensorflow:loss = 0.126019, step = 26804 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.142\n",
      "INFO:tensorflow:loss = 0.184193, step = 26904 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.118\n",
      "INFO:tensorflow:loss = 0.151926, step = 27004 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.956\n",
      "INFO:tensorflow:loss = 0.0634972, step = 27104 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.681\n",
      "INFO:tensorflow:loss = 0.157432, step = 27204 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217\n",
      "INFO:tensorflow:loss = 0.0728696, step = 27304 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.371\n",
      "INFO:tensorflow:loss = 0.0875168, step = 27404 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.534\n",
      "INFO:tensorflow:loss = 0.0317496, step = 27504 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.202\n",
      "INFO:tensorflow:loss = 0.151419, step = 27604 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.936\n",
      "INFO:tensorflow:loss = 0.0474359, step = 27704 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.009\n",
      "INFO:tensorflow:loss = 0.0775779, step = 27804 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.402\n",
      "INFO:tensorflow:loss = 0.105312, step = 27904 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.825\n",
      "INFO:tensorflow:loss = 0.123354, step = 28004 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.24\n",
      "INFO:tensorflow:loss = 0.0979254, step = 28104 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.525\n",
      "INFO:tensorflow:loss = 0.0470874, step = 28204 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.663\n",
      "INFO:tensorflow:loss = 0.119649, step = 28304 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.399\n",
      "INFO:tensorflow:loss = 0.0458525, step = 28404 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.693\n",
      "INFO:tensorflow:loss = 0.0774523, step = 28504 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.161\n",
      "INFO:tensorflow:loss = 0.175419, step = 28604 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.624\n",
      "INFO:tensorflow:loss = 0.206373, step = 28704 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.091\n",
      "INFO:tensorflow:loss = 0.076728, step = 28804 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.484\n",
      "INFO:tensorflow:loss = 0.112026, step = 28904 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.53\n",
      "INFO:tensorflow:loss = 0.0459183, step = 29004 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.911\n",
      "INFO:tensorflow:loss = 0.109632, step = 29104 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.3\n",
      "INFO:tensorflow:loss = 0.120359, step = 29204 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.766\n",
      "INFO:tensorflow:loss = 0.174296, step = 29304 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.085\n",
      "INFO:tensorflow:loss = 0.15264, step = 29404 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.26\n",
      "INFO:tensorflow:loss = 0.0482818, step = 29504 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.248\n",
      "INFO:tensorflow:loss = 0.192309, step = 29604 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.558\n",
      "INFO:tensorflow:loss = 0.097789, step = 29704 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.992\n",
      "INFO:tensorflow:loss = 0.105405, step = 29804 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.217\n",
      "INFO:tensorflow:loss = 0.0573617, step = 29904 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.103\n",
      "INFO:tensorflow:probabilities = [[ 0.99996269  0.00000008  0.00002575  0.0000004   0.00000005  0.00000304\n",
      "   0.0000038   0.00000256  0.00000077  0.00000098]\n",
      " [ 0.00033332  0.0005099   0.00222927  0.00035817  0.99413645  0.00018876\n",
      "   0.00035625  0.00129748  0.0000552   0.00053514]\n",
      " [ 0.00077727  0.00004813  0.00001463  0.0000256   0.00001214  0.99633139\n",
      "   0.00061538  0.00009408  0.0020579   0.00002353]\n",
      " [ 0.00836933  0.00000666  0.00001915  0.00002561  0.00002354  0.00143799\n",
      "   0.99011749  0.00000005  0.00000028  0.00000001]\n",
      " [ 0.00001342  0.00000213  0.00005317  0.99859482  0.          0.00130489\n",
      "   0.00000001  0.00000005  0.00000576  0.00002587]\n",
      " [ 0.00008781  0.00004063  0.99587113  0.00346105  0.00000006  0.0000015\n",
      "   0.0000005   0.00000136  0.00053568  0.00000023]\n",
      " [ 0.          0.0000004   0.00046281  0.00032352  0.00000005  0.00001194\n",
      "   0.00000004  0.00000032  0.99919981  0.00000102]\n",
      " [ 0.00000139  0.0002555   0.00026559  0.00012276  0.93930954  0.00044695\n",
      "   0.00002854  0.00064715  0.00123983  0.05768286]\n",
      " [ 0.00001751  0.0303553   0.00008171  0.0393355   0.30615595  0.00086293\n",
      "   0.00028     0.0001954   0.48689762  0.13581808]\n",
      " [ 0.00000041  0.00000187  0.99978834  0.00020795  0.00000002  0.00000006\n",
      "   0.00000004  0.          0.00000145  0.        ]\n",
      " [ 0.00166684  0.00004781  0.01186984  0.00000367  0.91682434  0.00013866\n",
      "   0.06917     0.00003383  0.00023832  0.0000065 ]\n",
      " [ 0.          0.00006492  0.00000814  0.00043696  0.00000563  0.0000138\n",
      "   0.0000012   0.00000081  0.99946517  0.00000344]\n",
      " [ 0.00001225  0.0000199   0.00024953  0.00683425  0.00004565  0.00006402\n",
      "   0.00000184  0.00000189  0.99175185  0.00101884]\n",
      " [ 0.00000694  0.00009914  0.00073211  0.00118378  0.00612113  0.00006461\n",
      "   0.00000262  0.00118086  0.00335347  0.98725533]\n",
      " [ 0.          0.00000005  0.99992144  0.00004841  0.00000047  0.00000004\n",
      "   0.          0.          0.00002967  0.00000001]\n",
      " [ 0.0000336   0.00013747  0.99916041  0.00028568  0.00000039  0.00001947\n",
      "   0.00000248  0.00005863  0.00026819  0.00003378]\n",
      " [ 0.00063635  0.0000265   0.00035908  0.07537889  0.00000358  0.92173702\n",
      "   0.00019238  0.00002246  0.00128781  0.00035601]\n",
      " [ 0.00000085  0.99867803  0.00013045  0.00002276  0.00007221  0.00000533\n",
      "   0.00001065  0.00099584  0.0000455   0.00003838]\n",
      " [ 0.00000937  0.00000001  0.00009121  0.00003299  0.00000128  0.00000054\n",
      "   0.00000001  0.          0.99986291  0.00000163]\n",
      " [ 0.0000002   0.00000021  0.00000187  0.00000004  0.00007913  0.00004806\n",
      "   0.99952638  0.          0.00034412  0.00000002]\n",
      " [ 0.00000019  0.00000154  0.00000461  0.00006041  0.03164914  0.00021884\n",
      "   0.00000352  0.00015439  0.00011142  0.96779603]\n",
      " [ 0.00002235  0.99844486  0.00016763  0.00000992  0.00000178  0.00000531\n",
      "   0.00003062  0.00025365  0.00106087  0.00000309]\n",
      " [ 0.0000399   0.16932809  0.0041158   0.00950963  0.54280329  0.01176689\n",
      "   0.00820664  0.00571476  0.10292909  0.14558594]\n",
      " [ 0.00000279  0.00000038  0.00000037  0.00000973  0.00000075  0.99960738\n",
      "   0.00002361  0.00000003  0.00025556  0.00009935]\n",
      " [ 0.02852846  0.00724876  0.02268855  0.78959244  0.00049956  0.11271617\n",
      "   0.02905309  0.00071283  0.00843825  0.00052197]\n",
      " [ 0.00001084  0.97787821  0.00011416  0.00020604  0.00005994  0.00033874\n",
      "   0.00094982  0.0000182   0.02036038  0.00006364]\n",
      " [ 0.00000004  0.00000526  0.00000239  0.00000146  0.99985397  0.0000028\n",
      "   0.00000794  0.00004078  0.00006755  0.00001774]\n",
      " [ 0.00000123  0.00000001  0.00126064  0.00000197  0.00000635  0.00001915\n",
      "   0.00012804  0.          0.99858248  0.0000001 ]\n",
      " [ 0.00000049  0.01122878  0.77404404  0.21453889  0.00000343  0.00013121\n",
      "   0.00000348  0.00002484  0.00002427  0.00000052]\n",
      " [ 0.00002874  0.0000291   0.00002768  0.00000377  0.00099552  0.00137814\n",
      "   0.99731207  0.00000188  0.00014927  0.00007384]\n",
      " [ 0.00000142  0.00000017  0.00002058  0.00000008  0.0005104   0.00001537\n",
      "   0.99943143  0.0000002   0.00001997  0.00000026]\n",
      " [ 0.00026706  0.01573266  0.00802948  0.07463208  0.00001631  0.00015524\n",
      "   0.00010262  0.00009542  0.89991415  0.00105493]\n",
      " [ 0.00000081  0.00000007  0.00000289  0.9979248   0.00000001  0.00078305\n",
      "   0.          0.00000035  0.00006297  0.00122503]\n",
      " [ 0.00004544  0.          0.          0.00000019  0.00006106  0.000132\n",
      "   0.00000008  0.99971753  0.00000004  0.00004365]\n",
      " [ 0.70017374  0.00035186  0.17095415  0.00128586  0.00197043  0.00068246\n",
      "   0.00266073  0.00471485  0.00006719  0.11713884]\n",
      " [ 0.00000336  0.00012742  0.00000453  0.99060798  0.0000025   0.00909922\n",
      "   0.00000056  0.00000049  0.00000747  0.00014659]\n",
      " [ 0.0000001   0.00000019  0.0000009   0.00000003  0.00002645  0.00003876\n",
      "   0.99993038  0.          0.00000317  0.00000001]\n",
      " [ 0.99999034  0.          0.00000003  0.          0.00000001  0.00000035\n",
      "   0.00000895  0.          0.00000001  0.00000034]\n",
      " [ 0.00010384  0.00000001  0.00000253  0.00000089  0.00002744  0.00000278\n",
      "   0.00000086  0.00037781  0.00001583  0.99946803]\n",
      " [ 0.00007533  0.00001839  0.00339684  0.00744791  0.00005058  0.00301567\n",
      "   0.00008545  0.00000662  0.98587102  0.00003219]\n",
      " [ 0.00001704  0.00000249  0.00129082  0.00000022  0.99849641  0.00002556\n",
      "   0.00009001  0.00000512  0.00002483  0.00004751]\n",
      " [ 0.00072665  0.33705357  0.00426429  0.04939521  0.00311861  0.00179767\n",
      "   0.00001882  0.2404239   0.02050931  0.34269196]\n",
      " [ 0.00000112  0.00001556  0.00009126  0.00006854  0.99281693  0.00001868\n",
      "   0.00001478  0.00085052  0.00005861  0.00606401]\n",
      " [ 0.00000005  0.00000097  0.00000236  0.00006202  0.72640944  0.00001584\n",
      "   0.00000206  0.02332144  0.00016158  0.25002423]\n",
      " [ 0.00000193  0.00000007  0.0000756   0.00004265  0.00000001  0.00000001\n",
      "   0.          0.99979097  0.00000402  0.00008473]\n",
      " [ 0.00000171  0.00000545  0.00847304  0.00103488  0.0000046   0.00000857\n",
      "   0.00000009  0.00025207  0.98943794  0.00078169]\n",
      " [ 0.00002379  0.00032832  0.00050928  0.00800963  0.00000053  0.98662901\n",
      "   0.00010626  0.00000069  0.00436195  0.00003059]\n",
      " [ 0.00032121  0.00000212  0.00000449  0.00001589  0.00009326  0.98611265\n",
      "   0.01292601  0.00004128  0.00047362  0.00000947]\n",
      " [ 0.00000367  0.00213223  0.00411388  0.01584356  0.00080593  0.00000791\n",
      "   0.00000169  0.97001249  0.0011927   0.00588605]\n",
      " [ 0.00001886  0.00075407  0.99904495  0.00003992  0.00002053  0.00000112\n",
      "   0.0001196   0.00000004  0.00000106  0.        ]\n",
      " [ 0.00001941  0.00000993  0.00308447  0.00476867  0.000067    0.00039048\n",
      "   0.00008195  0.00000335  0.99132383  0.00025088]\n",
      " [ 0.00013445  0.00000831  0.00043219  0.00001715  0.00000194  0.00000473\n",
      "   0.00001212  0.00000438  0.99929821  0.00008649]\n",
      " [ 0.          0.          0.00000006  0.          0.99999356  0.00000019\n",
      "   0.00000069  0.00000079  0.00000231  0.00000229]\n",
      " [ 0.00000023  0.00000005  0.00004028  0.00027238  0.00000024  0.00010169\n",
      "   0.00000047  0.00000082  0.99958366  0.00000022]\n",
      " [ 0.0000039   0.00000011  0.00001768  0.00000122  0.91455334  0.00002954\n",
      "   0.0000072   0.00012829  0.00003201  0.08522668]\n",
      " [ 0.99656421  0.00001025  0.00004685  0.00006694  0.          0.00329568\n",
      "   0.00000077  0.00000023  0.00001428  0.00000101]\n",
      " [ 0.00036627  0.00009328  0.00001434  0.00012697  0.00000039  0.99863154\n",
      "   0.00008985  0.00002574  0.00064949  0.00000203]\n",
      " [ 0.00000003  0.00000009  0.00000011  0.00001521  0.00000008  0.00000119\n",
      "   0.          0.9996208   0.00000008  0.0003624 ]\n",
      " [ 0.00000793  0.99843198  0.00020004  0.00014796  0.00006375  0.00000522\n",
      "   0.00001715  0.00056766  0.00043505  0.00012321]\n",
      " [ 0.00007185  0.00172938  0.0251566   0.02259968  0.00000722  0.00146052\n",
      "   0.00030241  0.00001159  0.94849688  0.0001638 ]\n",
      " [ 0.00011852  0.00328437  0.00887377  0.00606377  0.03855315  0.00217027\n",
      "   0.91186619  0.0000061   0.02905371  0.00001019]\n",
      " [ 0.00000018  0.0000003   0.00000023  0.01249535  0.00000304  0.97804433\n",
      "   0.00000089  0.00000021  0.00072415  0.00873124]\n",
      " [ 0.99995685  0.00000001  0.00000722  0.00000004  0.00000003  0.00001569\n",
      "   0.00000075  0.00001472  0.00000092  0.00000368]\n",
      " [ 0.92115158  0.00007367  0.00004243  0.02052202  0.00002619  0.05208325\n",
      "   0.00001649  0.00266889  0.00172147  0.001694  ]\n",
      " [ 0.00000046  0.00001673  0.00000697  0.00000374  0.99500352  0.00002182\n",
      "   0.00025297  0.00031879  0.00004607  0.0043289 ]\n",
      " [ 0.00003792  0.00018833  0.00002215  0.000768    0.00001162  0.99879241\n",
      "   0.0000175   0.00001914  0.00012343  0.00001936]\n",
      " [ 0.00002013  0.9335466   0.01001216  0.00092291  0.00000014  0.0008246\n",
      "   0.00002996  0.0000013   0.05463842  0.00000362]\n",
      " [ 0.00013769  0.00019878  0.00001796  0.00012558  0.00002698  0.98894775\n",
      "   0.00608287  0.00003135  0.00374573  0.00068521]\n",
      " [ 0.99992943  0.00000003  0.00002227  0.00000185  0.          0.00001809\n",
      "   0.00000047  0.00002629  0.00000053  0.00000092]\n",
      " [ 0.0000037   0.99556041  0.00006158  0.0004634   0.00030193  0.00000078\n",
      "   0.0000037   0.0006622   0.00067546  0.00226681]\n",
      " [ 0.          0.00000001  0.99997878  0.00002114  0.00000001  0.          0.\n",
      "   0.          0.00000017  0.        ]\n",
      " [ 0.98230237  0.00041204  0.00140736  0.00029561  0.00018276  0.00430137\n",
      "   0.00036885  0.01034547  0.00031174  0.00007233]\n",
      " [ 0.00000025  0.00000351  0.95988417  0.02303099  0.00000435  0.00001827\n",
      "   0.00000013  0.00000734  0.01703537  0.00001568]\n",
      " [ 0.00015276  0.00059844  0.00048362  0.00660777  0.00012341  0.0050634\n",
      "   0.00007855  0.00000888  0.98585212  0.00103101]\n",
      " [ 0.00000799  0.99897754  0.00007113  0.00002449  0.00006155  0.00001018\n",
      "   0.00000369  0.00070496  0.00012305  0.00001547]\n",
      " [ 0.00009441  0.00008695  0.91453707  0.08335882  0.00005081  0.0000062\n",
      "   0.00002096  0.00063782  0.0011933   0.0000136 ]\n",
      " [ 0.00001393  0.99841678  0.00003225  0.00002577  0.00001733  0.00000983\n",
      "   0.00011101  0.00008049  0.00127942  0.00001297]\n",
      " [ 0.00006453  0.00002834  0.84651226  0.15254901  0.00000113  0.00006121\n",
      "   0.0000034   0.00023531  0.00052614  0.00001857]\n",
      " [ 0.00000001  0.00004582  0.00001303  0.99831784  0.00000184  0.00035328\n",
      "   0.00000006  0.00001421  0.00111191  0.00014198]\n",
      " [ 0.00000939  0.00006524  0.00190432  0.00026522  0.99443793  0.00009764\n",
      "   0.00009855  0.0000526   0.00003756  0.00303146]\n",
      " [ 0.          0.00000029  0.00000138  0.99997044  0.          0.00001763\n",
      "   0.          0.00000002  0.00000101  0.00000927]\n",
      " [ 0.00000011  0.99995363  0.00000314  0.00000334  0.00001108  0.00000016\n",
      "   0.00000082  0.00001886  0.00000858  0.00000039]\n",
      " [ 0.00000449  0.99942005  0.00014222  0.0000831   0.00005331  0.00001152\n",
      "   0.00001564  0.00014638  0.00008426  0.00003899]\n",
      " [ 0.00001118  0.0000183   0.00002399  0.00000287  0.00001082  0.00078693\n",
      "   0.9989717   0.00000001  0.0001742   0.00000001]\n",
      " [ 0.          0.          0.00000259  0.00001091  0.          0.          0.\n",
      "   0.99996901  0.00000002  0.00001749]\n",
      " [ 0.02574782  0.00784354  0.64621711  0.17174016  0.00183509  0.05314944\n",
      "   0.0004318   0.0141969   0.07197285  0.00686537]\n",
      " [ 0.00000854  0.00004558  0.0003801   0.00068411  0.00361131  0.00004276\n",
      "   0.00000357  0.00161171  0.00381766  0.98979467]\n",
      " [ 0.00072997  0.00000798  0.00000436  0.00000063  0.00017468  0.00154656\n",
      "   0.99737453  0.00000017  0.00014579  0.00001544]\n",
      " [ 0.00169066  0.00141587  0.45900479  0.00597649  0.09308881  0.00225975\n",
      "   0.0002439   0.39527518  0.00390343  0.03714114]\n",
      " [ 0.000001    0.          0.00000132  0.          0.00096785  0.00000171\n",
      "   0.99902773  0.00000001  0.00000014  0.0000002 ]\n",
      " [ 0.          0.00000001  0.99992192  0.0000781   0.          0.          0.\n",
      "   0.          0.00000003  0.        ]\n",
      " [ 0.00000632  0.00184786  0.0022247   0.00302313  0.00000014  0.0000002\n",
      "   0.          0.99189997  0.0001166   0.00088118]\n",
      " [ 0.00000024  0.00000015  0.00005468  0.00004065  0.          0.00000023\n",
      "   0.          0.99980563  0.00000008  0.00009829]\n",
      " [ 0.99994922  0.00000045  0.00000292  0.00000585  0.00000007  0.0000067\n",
      "   0.00003408  0.00000015  0.00000011  0.00000049]\n",
      " [ 0.00072359  0.000061    0.00002159  0.00003095  0.00010439  0.00040082\n",
      "   0.9985078   0.00000001  0.00014808  0.00000175]\n",
      " [ 0.00001242  0.00000082  0.00003644  0.00004758  0.00520506  0.00000314\n",
      "   0.00000238  0.00644159  0.00023113  0.98801941]\n",
      " [ 0.0000309   0.00000172  0.00000741  0.00000009  0.00017412  0.0000515\n",
      "   0.99972409  0.00000003  0.00000984  0.00000018]\n",
      " [ 0.00000526  0.77037209  0.00275138  0.06258184  0.00051663  0.00008673\n",
      "   0.00000329  0.15477571  0.00679175  0.00211524]\n",
      " [ 0.00002412  0.01198236  0.84849489  0.01414727  0.00282263  0.00256244\n",
      "   0.00132655  0.11713366  0.001169    0.00033721]\n",
      " [ 0.00000024  0.00000002  0.00000362  0.00000007  0.9999522   0.00000004\n",
      "   0.00002089  0.00000516  0.00000115  0.00001674]] (23.280 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.117601, step = 30004 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.164\n",
      "INFO:tensorflow:loss = 0.135572, step = 30104 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.166\n",
      "INFO:tensorflow:loss = 0.173473, step = 30204 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.29\n",
      "INFO:tensorflow:loss = 0.0499308, step = 30304 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.398\n",
      "INFO:tensorflow:loss = 0.116598, step = 30404 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.502\n",
      "INFO:tensorflow:loss = 0.0395054, step = 30504 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.271\n",
      "INFO:tensorflow:loss = 0.0844747, step = 30604 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.415\n",
      "INFO:tensorflow:loss = 0.082434, step = 30704 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.111\n",
      "INFO:tensorflow:loss = 0.138741, step = 30804 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.921\n",
      "INFO:tensorflow:loss = 0.0459335, step = 30904 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.377\n",
      "INFO:tensorflow:loss = 0.0680041, step = 31004 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.504\n",
      "INFO:tensorflow:loss = 0.0734091, step = 31104 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.894\n",
      "INFO:tensorflow:loss = 0.0569892, step = 31204 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.212\n",
      "INFO:tensorflow:loss = 0.132291, step = 31304 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.003\n",
      "INFO:tensorflow:loss = 0.109309, step = 31404 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.819\n",
      "INFO:tensorflow:loss = 0.0440179, step = 31504 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.832\n",
      "INFO:tensorflow:loss = 0.106813, step = 31604 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.04\n",
      "INFO:tensorflow:loss = 0.0955185, step = 31704 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.706\n",
      "INFO:tensorflow:loss = 0.118843, step = 31804 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.88\n",
      "INFO:tensorflow:loss = 0.0744739, step = 31904 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.09\n",
      "INFO:tensorflow:loss = 0.138635, step = 32004 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.309\n",
      "INFO:tensorflow:loss = 0.11297, step = 32104 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.216\n",
      "INFO:tensorflow:loss = 0.187136, step = 32204 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.615\n",
      "INFO:tensorflow:loss = 0.10024, step = 32304 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.038\n",
      "INFO:tensorflow:loss = 0.0391062, step = 32404 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.676\n",
      "INFO:tensorflow:loss = 0.0872068, step = 32504 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.147\n",
      "INFO:tensorflow:loss = 0.0534241, step = 32604 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.995\n",
      "INFO:tensorflow:loss = 0.0513832, step = 32704 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.576\n",
      "INFO:tensorflow:loss = 0.0676959, step = 32804 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.557\n",
      "INFO:tensorflow:loss = 0.113376, step = 32904 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.016\n",
      "INFO:tensorflow:loss = 0.0308205, step = 33004 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.354\n",
      "INFO:tensorflow:loss = 0.0726456, step = 33104 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.083\n",
      "INFO:tensorflow:loss = 0.0774641, step = 33204 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.137\n",
      "INFO:tensorflow:loss = 0.0853669, step = 33304 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.696\n",
      "INFO:tensorflow:loss = 0.0149144, step = 33404 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.864\n",
      "INFO:tensorflow:loss = 0.0587158, step = 33504 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.367\n",
      "INFO:tensorflow:loss = 0.0683749, step = 33604 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.971\n",
      "INFO:tensorflow:loss = 0.0341462, step = 33704 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.216\n",
      "INFO:tensorflow:loss = 0.14817, step = 33804 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.574\n",
      "INFO:tensorflow:loss = 0.130088, step = 33904 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.072\n",
      "INFO:tensorflow:loss = 0.110884, step = 34004 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.703\n",
      "INFO:tensorflow:loss = 0.137565, step = 34104 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.901\n",
      "INFO:tensorflow:loss = 0.0982647, step = 34204 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.163\n",
      "INFO:tensorflow:loss = 0.058321, step = 34304 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.427\n",
      "INFO:tensorflow:loss = 0.027069, step = 34404 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.846\n",
      "INFO:tensorflow:loss = 0.0420205, step = 34504 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.457\n",
      "INFO:tensorflow:loss = 0.0822105, step = 34604 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.419\n",
      "INFO:tensorflow:loss = 0.0857335, step = 34704 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.071\n",
      "INFO:tensorflow:loss = 0.065692, step = 34804 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.581\n",
      "INFO:tensorflow:loss = 0.0506226, step = 34904 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.484\n",
      "INFO:tensorflow:probabilities = [[ 0.00000057  0.99944776  0.00001705  0.00003367  0.00006323  0.00000225\n",
      "   0.00000085  0.00006536  0.00027404  0.00009505]\n",
      " [ 0.00000009  0.00000191  0.00003116  0.99987388  0.00000028  0.00007597\n",
      "   0.00000004  0.00000002  0.00001618  0.00000065]\n",
      " [ 0.00000463  0.00000002  0.99556446  0.00082375  0.          0.00000014\n",
      "   0.00000002  0.00360124  0.00000542  0.00000038]\n",
      " [ 0.          0.00000002  0.00000011  0.99996722  0.          0.00003257\n",
      "   0.          0.          0.00000003  0.00000017]\n",
      " [ 0.00000014  0.00000035  0.00000091  0.00000025  0.99992919  0.00000799\n",
      "   0.00000167  0.00000509  0.00000038  0.00005401]\n",
      " [ 0.00000005  0.00000144  0.00004906  0.99993682  0.          0.00001255\n",
      "   0.00000005  0.00000002  0.00000016  0.00000001]\n",
      " [ 0.00000002  0.00000001  0.00000173  0.01588974  0.00000015  0.98294556\n",
      "   0.00000001  0.00000608  0.00026453  0.0008921 ]\n",
      " [ 0.00000002  0.00000007  0.00002072  0.00030052  0.00086007  0.00016398\n",
      "   0.00000002  0.00020928  0.000105    0.99834025]\n",
      " [ 0.00000001  0.00021701  0.94315857  0.05535263  0.00000011  0.00000094\n",
      "   0.00000006  0.00125886  0.00000874  0.00000304]\n",
      " [ 0.99770373  0.00000009  0.00001809  0.00000006  0.          0.00224245\n",
      "   0.00003072  0.00000484  0.00000003  0.00000001]\n",
      " [ 0.00002337  0.00000506  0.00086822  0.00000448  0.00024281  0.00014187\n",
      "   0.99870229  0.00000205  0.00000992  0.00000004]\n",
      " [ 0.00000009  0.00000019  0.0000009   0.00000553  0.99935621  0.00000498\n",
      "   0.00000199  0.00010603  0.00000089  0.00052318]\n",
      " [ 0.000023    0.17684016  0.70175916  0.05245779  0.00021035  0.00069553\n",
      "   0.00143505  0.06221307  0.00433522  0.00003074]\n",
      " [ 0.00000066  0.00000061  0.0001306   0.00186367  0.00000081  0.0000454\n",
      "   0.00000006  0.00000633  0.99787915  0.00007264]\n",
      " [ 0.00002216  0.99601352  0.00056136  0.00016973  0.00002942  0.00000468\n",
      "   0.00003551  0.00108291  0.00182562  0.00025521]\n",
      " [ 0.          0.00000113  0.00000303  0.0000003   0.99993742  0.00000008\n",
      "   0.00000247  0.00002768  0.00000547  0.00002243]\n",
      " [ 0.00001908  0.00004057  0.00268046  0.96994746  0.00000241  0.00279689\n",
      "   0.00000836  0.00000003  0.02395953  0.00054531]\n",
      " [ 0.00000049  0.00000002  0.00000073  0.00003092  0.          0.          0.\n",
      "   0.99889117  0.          0.00107674]\n",
      " [ 0.00000085  0.99714583  0.00002004  0.00009384  0.00039896  0.00003366\n",
      "   0.00103095  0.00000199  0.00127078  0.00000309]\n",
      " [ 0.99999797  0.          0.00000126  0.          0.          0.00000026\n",
      "   0.00000049  0.          0.          0.00000001]\n",
      " [ 0.00000055  0.00000013  0.00000212  0.00007879  0.00660625  0.00003318\n",
      "   0.00000069  0.00012165  0.00036895  0.99278766]\n",
      " [ 0.00000041  0.00000023  0.00001371  0.0000803   0.00000449  0.0000301\n",
      "   0.00000034  0.0000002   0.99986005  0.00001016]\n",
      " [ 0.00000192  0.00000348  0.00000991  0.00011307  0.00000007  0.00000303\n",
      "   0.          0.99964345  0.0000006   0.00022453]\n",
      " [ 0.00000045  0.00076124  0.00005171  0.00316635  0.00049684  0.00023507\n",
      "   0.00087091  0.00005155  0.99435788  0.00000793]\n",
      " [ 0.99998808  0.          0.0000001   0.          0.          0.0000054\n",
      "   0.          0.00000585  0.          0.00000061]\n",
      " [ 0.0000003   0.00000001  0.00002449  0.00069621  0.          0.00000157\n",
      "   0.          0.99920952  0.00000007  0.00006775]\n",
      " [ 0.01844869  0.04379594  0.0218544   0.70348942  0.00063338  0.03836311\n",
      "   0.00012866  0.00564663  0.11588565  0.05175403]\n",
      " [ 0.00000508  0.00000004  0.00000057  0.00002597  0.00000005  0.99949491\n",
      "   0.00015798  0.00000001  0.00029777  0.00001761]\n",
      " [ 0.00012838  0.00000622  0.00008088  0.00000364  0.00090761  0.00010166\n",
      "   0.99876499  0.00000006  0.00000643  0.00000029]\n",
      " [ 0.00007671  0.0000262   0.01253967  0.00000219  0.00071313  0.0003085\n",
      "   0.9863115   0.00000219  0.00001978  0.00000007]\n",
      " [ 0.00000001  0.00008272  0.9995153   0.00038776  0.00000542  0.00000021\n",
      "   0.00000041  0.00000008  0.0000082   0.00000001]\n",
      " [ 0.00001442  0.00000003  0.00076977  0.00040493  0.00000599  0.00000021\n",
      "   0.00000001  0.0036637   0.00013355  0.9950074 ]\n",
      " [ 0.00000116  0.          0.00000003  0.          0.00130585  0.00002483\n",
      "   0.99866784  0.          0.00000007  0.00000019]\n",
      " [ 0.00001515  0.00001051  0.00025559  0.00008789  0.00000273  0.00003261\n",
      "   0.00001345  0.00000236  0.99955505  0.00002461]\n",
      " [ 0.00000763  0.00000088  0.00007056  0.0010586   0.00000051  0.00279388\n",
      "   0.00000251  0.00000002  0.99605983  0.00000558]\n",
      " [ 0.00005613  0.97885269  0.0008942   0.00149998  0.00027643  0.00001505\n",
      "   0.00008859  0.01744834  0.00032681  0.0005418 ]\n",
      " [ 0.          0.00000001  0.00000001  0.0000001   0.99996209  0.0000001\n",
      "   0.          0.00000009  0.00000353  0.00003399]\n",
      " [ 0.00319168  0.00006693  0.02353313  0.00001755  0.81041306  0.00055312\n",
      "   0.16130164  0.0003977   0.00037327  0.00015191]\n",
      " [ 0.00000425  0.00000317  0.00029987  0.00000417  0.00001563  0.00011013\n",
      "   0.99955553  0.          0.0000073   0.00000001]\n",
      " [ 0.0000004   0.00000016  0.00000057  0.00000001  0.00000159  0.00000644\n",
      "   0.99998987  0.          0.00000096  0.00000002]\n",
      " [ 0.0000302   0.99420738  0.00076429  0.0001355   0.00022194  0.00001641\n",
      "   0.0001366   0.00039143  0.00405964  0.00003652]\n",
      " [ 0.          0.          0.00002802  0.99974304  0.          0.00000001\n",
      "   0.          0.00000001  0.00022888  0.0000001 ]\n",
      " [ 0.00000007  0.00000046  0.00000185  0.00000101  0.9997223   0.00007557\n",
      "   0.0000189   0.00002386  0.00000241  0.00015359]\n",
      " [ 0.00000021  0.00000009  0.00001213  0.00021889  0.00001437  0.00126187\n",
      "   0.00000012  0.00001687  0.99847442  0.00000103]\n",
      " [ 0.00000394  0.00001016  0.00009375  0.00090387  0.00001424  0.00013708\n",
      "   0.00000221  0.00000071  0.99870479  0.00012926]\n",
      " [ 0.00001795  0.00024719  0.00042189  0.00000446  0.00026746  0.00033571\n",
      "   0.99558467  0.00000071  0.0031123   0.00000759]\n",
      " [ 0.00003102  0.99177951  0.00027464  0.000863    0.00084234  0.0002081\n",
      "   0.00030546  0.00096095  0.00226208  0.00247288]\n",
      " [ 0.00000004  0.00000052  0.00001686  0.00000008  0.00000199  0.00046504\n",
      "   0.99950182  0.          0.00001293  0.00000061]\n",
      " [ 0.00000004  0.00000003  0.00038436  0.00051688  0.00000072  0.00000004\n",
      "   0.          0.99902093  0.00000198  0.00007487]\n",
      " [ 0.00000682  0.00014991  0.00000587  0.00020626  0.42532903  0.0001695\n",
      "   0.00000342  0.00012225  0.00887674  0.56513017]\n",
      " [ 0.0001015   0.00002074  0.00096197  0.0326428   0.0002127   0.86042303\n",
      "   0.00440692  0.00006053  0.10008542  0.00108441]\n",
      " [ 0.00022775  0.00000094  0.00033701  0.00014046  0.00000167  0.00000684\n",
      "   0.00000035  0.99462527  0.00001583  0.00464395]\n",
      " [ 0.00000971  0.00000036  0.00000217  0.00000038  0.00004071  0.00060618\n",
      "   0.99900693  0.          0.00033332  0.00000023]\n",
      " [ 0.          0.00005913  0.99993491  0.00000594  0.          0.00000003\n",
      "   0.00000002  0.00000001  0.00000002  0.        ]\n",
      " [ 0.00040805  0.00000362  0.00004355  0.00000039  0.00052844  0.00004257\n",
      "   0.99891376  0.00001928  0.00002966  0.00001069]\n",
      " [ 0.00001439  0.00000016  0.00000502  0.00062907  0.00124773  0.00005165\n",
      "   0.00000103  0.00034455  0.00050382  0.99720263]\n",
      " [ 0.00028255  0.00016458  0.00078078  0.00946749  0.00004157  0.98834723\n",
      "   0.00023317  0.0003881   0.00017992  0.00011467]\n",
      " [ 0.99932086  0.00000035  0.00005243  0.00000491  0.00000971  0.00008111\n",
      "   0.0003977   0.00000298  0.00000905  0.0001209 ]\n",
      " [ 0.00000292  0.00000471  0.99947041  0.00001671  0.00047353  0.00000038\n",
      "   0.00000002  0.00000069  0.00002643  0.00000431]\n",
      " [ 0.00000129  0.99947637  0.00001144  0.00003283  0.00003589  0.00000679\n",
      "   0.00000197  0.00021001  0.00016394  0.0000593 ]\n",
      " [ 0.00067689  0.00041044  0.00047744  0.95571351  0.00001129  0.04103938\n",
      "   0.00000261  0.00016387  0.00021453  0.00129017]\n",
      " [ 0.00000092  0.0000003   0.00000642  0.00000039  0.99928683  0.00002895\n",
      "   0.00005615  0.00001476  0.00000379  0.00060145]\n",
      " [ 0.00001402  0.99771899  0.00030829  0.00033666  0.00015772  0.00003457\n",
      "   0.00004478  0.00075988  0.0005022   0.00012274]\n",
      " [ 0.00000004  0.0000001   0.00005228  0.01605612  0.00000006  0.98264831\n",
      "   0.00000025  0.00000003  0.00123514  0.00000771]\n",
      " [ 0.99923587  0.          0.00004144  0.00000028  0.00000726  0.0000138\n",
      "   0.00069943  0.00000029  0.00000055  0.00000108]\n",
      " [ 0.00000464  0.00000028  0.00065423  0.00055659  0.00000805  0.00004721\n",
      "   0.00000066  0.00000107  0.9984675   0.00025972]\n",
      " [ 0.00000727  0.0000022   0.00000126  0.0000031   0.00000587  0.00071881\n",
      "   0.99919933  0.          0.00006207  0.00000008]\n",
      " [ 0.00358724  0.00087539  0.01587362  0.00146842  0.01985689  0.00009046\n",
      "   0.00016183  0.00202608  0.0071932   0.94886684]\n",
      " [ 0.00000002  0.00001667  0.9975369   0.00241889  0.          0.00000011\n",
      "   0.00000001  0.00000022  0.0000272   0.        ]\n",
      " [ 0.00000054  0.00000619  0.97833669  0.02109832  0.          0.00000021\n",
      "   0.          0.00004156  0.00051628  0.00000014]\n",
      " [ 0.00000163  0.00013075  0.00003938  0.00219035  0.03759029  0.94931942\n",
      "   0.00165919  0.00001417  0.00346778  0.00558714]\n",
      " [ 0.00000333  0.0001069   0.00055939  0.00017987  0.9952544   0.00000973\n",
      "   0.00007069  0.00198302  0.00004256  0.00179013]\n",
      " [ 0.00000022  0.00000009  0.00000578  0.98694789  0.00000056  0.00010533\n",
      "   0.00000001  0.00001664  0.01285837  0.00006519]\n",
      " [ 0.00007267  0.00000013  0.00001871  0.99780124  0.00000018  0.0003752\n",
      "   0.00000015  0.00000004  0.00148395  0.00024771]\n",
      " [ 0.00106461  0.0001586   0.00005805  0.00000774  0.00002431  0.71197331\n",
      "   0.28619584  0.00004007  0.00044784  0.00002955]\n",
      " [ 0.00086955  0.          0.99906033  0.00003798  0.00000003  0.00000005\n",
      "   0.00000001  0.0000317   0.00000049  0.00000006]\n",
      " [ 0.00000008  0.00000532  0.00000498  0.00013437  0.00000011  0.00000089\n",
      "   0.          0.99915242  0.00000106  0.00070066]\n",
      " [ 0.00000003  0.00000003  0.00000001  0.00000037  0.99952495  0.00000435\n",
      "   0.00000059  0.00007228  0.00006779  0.00032942]\n",
      " [ 0.99963057  0.00001225  0.00005419  0.00000472  0.00000059  0.00027912\n",
      "   0.00001578  0.00000031  0.00000017  0.00000224]\n",
      " [ 0.00000008  0.          0.00000113  0.00012316  0.00057071  0.00016255\n",
      "   0.00000003  0.00026494  0.00002997  0.99884737]\n",
      " [ 0.0000172   0.00000006  0.00004999  0.00066289  0.00000018  0.0000326\n",
      "   0.          0.9986499   0.00000435  0.00058288]\n",
      " [ 0.00000015  0.00254344  0.00012856  0.00047171  0.00006668  0.00000072\n",
      "   0.00000004  0.99631602  0.0002115   0.00026117]\n",
      " [ 0.00000145  0.00000267  0.00001133  0.00000945  0.99001265  0.00000094\n",
      "   0.00000111  0.00118515  0.00616283  0.00261241]\n",
      " [ 0.00000118  0.00000784  0.00000568  0.91260058  0.00192107  0.01662955\n",
      "   0.00000132  0.00000281  0.00070105  0.06812897]\n",
      " [ 0.00001062  0.00000366  0.00005337  0.00034703  0.00447446  0.00003271\n",
      "   0.00000044  0.00042117  0.00028934  0.99436718]\n",
      " [ 0.00000191  0.00289182  0.98797053  0.004233    0.0000401   0.00001749\n",
      "   0.00001466  0.00400991  0.00080767  0.00001295]\n",
      " [ 0.00000002  0.00000002  0.00000011  0.00023421  0.00000571  0.0000184\n",
      "   0.          0.00006258  0.00001035  0.9996686 ]\n",
      " [ 0.99266124  0.0000014   0.00029954  0.00000334  0.00004901  0.00017024\n",
      "   0.00671858  0.00000669  0.00008799  0.00000198]\n",
      " [ 0.00021227  0.00108239  0.76193875  0.01887623  0.00000399  0.0003375\n",
      "   0.00001606  0.216416    0.00011729  0.00099953]\n",
      " [ 0.00000002  0.00000028  0.99999201  0.00000339  0.00000212  0.00000005\n",
      "   0.00000212  0.          0.0000001   0.00000001]\n",
      " [ 0.00092938  0.01393217  0.00006548  0.00983955  0.15538904  0.02299862\n",
      "   0.00032025  0.00663357  0.10028974  0.6896022 ]\n",
      " [ 0.00000001  0.0000001   0.00116236  0.00001065  0.9987852   0.00000339\n",
      "   0.00000026  0.00000103  0.00000695  0.00003006]\n",
      " [ 0.00003387  0.00000274  0.00389094  0.00234894  0.00126506  0.00000774\n",
      "   0.00000529  0.91888595  0.00010895  0.0734505 ]\n",
      " [ 0.00000084  0.99238753  0.00000573  0.00000306  0.00000078  0.00000718\n",
      "   0.00000157  0.00000048  0.00759147  0.00000146]\n",
      " [ 0.00019515  0.00000812  0.00005711  0.00001454  0.00958632  0.00009953\n",
      "   0.98889917  0.0008502   0.00027627  0.00001359]\n",
      " [ 0.00107436  0.00035662  0.00006196  0.00102824  0.03491596  0.00730351\n",
      "   0.00002655  0.09327702  0.00003639  0.8619194 ]\n",
      " [ 0.00000036  0.01282255  0.78336936  0.19393985  0.00003526  0.00000461\n",
      "   0.00000149  0.00776543  0.00205848  0.00000265]\n",
      " [ 0.0000266   0.00000995  0.00002326  0.00016978  0.00093317  0.00001336\n",
      "   0.00000021  0.00604374  0.00016946  0.99261051]\n",
      " [ 0.00000665  0.99807394  0.00030531  0.00030231  0.00029118  0.00001492\n",
      "   0.00001933  0.00058406  0.00031003  0.00009227]\n",
      " [ 0.99986601  0.00000005  0.00013002  0.00000012  0.          0.00000331\n",
      "   0.0000004   0.00000002  0.00000002  0.00000007]] (23.248 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0661207, step = 35004 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.876\n",
      "INFO:tensorflow:loss = 0.109769, step = 35104 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.19\n",
      "INFO:tensorflow:loss = 0.10192, step = 35204 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.886\n",
      "INFO:tensorflow:loss = 0.127737, step = 35304 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.691\n",
      "INFO:tensorflow:loss = 0.0419498, step = 35404 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.583\n",
      "INFO:tensorflow:loss = 0.216545, step = 35504 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.811\n",
      "INFO:tensorflow:loss = 0.0989907, step = 35604 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.053\n",
      "INFO:tensorflow:loss = 0.0496074, step = 35704 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.432\n",
      "INFO:tensorflow:loss = 0.0964368, step = 35804 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.507\n",
      "INFO:tensorflow:loss = 0.088836, step = 35904 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.543\n",
      "INFO:tensorflow:loss = 0.0966087, step = 36004 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.575\n",
      "INFO:tensorflow:loss = 0.0530457, step = 36104 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.596\n",
      "INFO:tensorflow:loss = 0.0952119, step = 36204 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.694\n",
      "INFO:tensorflow:loss = 0.0297675, step = 36304 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.656\n",
      "INFO:tensorflow:loss = 0.109475, step = 36404 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.739\n",
      "INFO:tensorflow:loss = 0.0852375, step = 36504 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.679\n",
      "INFO:tensorflow:loss = 0.132574, step = 36604 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.844\n",
      "INFO:tensorflow:loss = 0.0200197, step = 36704 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.587\n",
      "INFO:tensorflow:loss = 0.0730495, step = 36804 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.003\n",
      "INFO:tensorflow:loss = 0.0695385, step = 36904 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.537\n",
      "INFO:tensorflow:loss = 0.0807047, step = 37004 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.292\n",
      "INFO:tensorflow:loss = 0.0192925, step = 37104 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.748\n",
      "INFO:tensorflow:loss = 0.0698587, step = 37204 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.805\n",
      "INFO:tensorflow:loss = 0.0264501, step = 37304 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.558\n",
      "INFO:tensorflow:loss = 0.068363, step = 37404 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.441\n",
      "INFO:tensorflow:loss = 0.119115, step = 37504 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.879\n",
      "INFO:tensorflow:loss = 0.0310108, step = 37604 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.886\n",
      "INFO:tensorflow:loss = 0.0772633, step = 37704 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.501\n",
      "INFO:tensorflow:loss = 0.173939, step = 37804 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.217\n",
      "INFO:tensorflow:loss = 0.0613209, step = 37904 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.812\n",
      "INFO:tensorflow:loss = 0.182449, step = 38004 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.492\n",
      "INFO:tensorflow:loss = 0.0808961, step = 38104 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.372\n",
      "INFO:tensorflow:loss = 0.0814225, step = 38204 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.507\n",
      "INFO:tensorflow:loss = 0.108977, step = 38304 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.319\n",
      "INFO:tensorflow:loss = 0.0356911, step = 38404 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.788\n",
      "INFO:tensorflow:loss = 0.0397831, step = 38504 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.845\n",
      "INFO:tensorflow:loss = 0.0561465, step = 38604 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.739\n",
      "INFO:tensorflow:loss = 0.0252543, step = 38704 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.712\n",
      "INFO:tensorflow:loss = 0.101764, step = 38804 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.615\n",
      "INFO:tensorflow:loss = 0.0646066, step = 38904 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.615\n",
      "INFO:tensorflow:loss = 0.141347, step = 39004 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.788\n",
      "INFO:tensorflow:loss = 0.0763849, step = 39104 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.942\n",
      "INFO:tensorflow:loss = 0.106222, step = 39204 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.81\n",
      "INFO:tensorflow:loss = 0.101309, step = 39304 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.119\n",
      "INFO:tensorflow:loss = 0.0771185, step = 39404 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.311\n",
      "INFO:tensorflow:loss = 0.0252706, step = 39504 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.48\n",
      "INFO:tensorflow:loss = 0.0915553, step = 39604 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.547\n",
      "INFO:tensorflow:loss = 0.0963515, step = 39704 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.717\n",
      "INFO:tensorflow:loss = 0.0858645, step = 39804 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.682\n",
      "INFO:tensorflow:loss = 0.0466552, step = 39904 (0.479 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40003 into /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.20754.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x2b8a3ed4d30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-04-05:17:41\n",
      "INFO:tensorflow:Restoring parameters from /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt-40003\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-04-05:17:42\n",
      "INFO:tensorflow:Saving dict for global step 40003: accuracy = 0.9801, global_step = 40003, loss = 0.064799\n",
      "{'accuracy': 0.98009998, 'loss': 0.064799033, 'global_step': 40003}\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "        model_fn=cnn_model_fn, \n",
    "        model_dir=\"/home/w/tmp/tensorflow/mnist_convnet_model\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=5000)\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": train_data},\n",
    "  y=train_labels,\n",
    "  batch_size=100,\n",
    "  num_epochs=None,\n",
    "  shuffle=True)\n",
    "mnist_classifier.train(\n",
    "  input_fn=train_input_fn,\n",
    "  steps=20000,\n",
    "  hooks=[logging_hook])\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": eval_data},\n",
    "  y=eval_labels,\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单的单层dnn网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/w/tmp/tensorflow/mnist/input_data\\train-images-idx3-ubyte.gz\n",
      "Extracting /home/w/tmp/tensorflow/mnist/input_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /home/w/tmp/tensorflow/mnist/input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/w/tmp/tensorflow/mnist/input_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Read in the MNIST dataset\n",
    "mnist = input_data.read_data_sets(\"/home/w/tmp/tensorflow/mnist/input_data\", one_hot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x00000214801C5D68>, 'hidden_units': [1024], 'feature_columns': (_RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': <tensorflow.python.training.adam.AdamOptimizer object at 0x00000214801C5D30>, 'activation_fn': <function relu at 0x000002122169A048>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.97390002, 'global_step': 1000, 'loss': 0.083541602}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define estimator \n",
    "classifier=tf.contrib.learn.DNNClassifier(\n",
    "                    feature_columns=[tf.contrib.layers.real_valued_column('',dimension=28*28)],\n",
    "                    hidden_units=[1024],\n",
    "                    n_classes=10,\n",
    "                    optimizer=tf.train.AdamOptimizer())\n",
    "\n",
    "# training\n",
    "classifier.fit(x=mnist.train.images,\n",
    "                   y=mnist.train.labels.astype(np.int32),\n",
    "                   batch_size=100,\n",
    "                   steps=1000)\n",
    "\n",
    "# test\n",
    "classifier.evaluate(x=mnist.test.images,\n",
    "                   y=mnist.test.labels.astype(np.int32),\n",
    "                   steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复杂的cnn网络\n",
    "https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/examples/tutorials/layers/cnn_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/w/tmp/tensorflow/mnist_convnet_model', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt-67003\n",
      "INFO:tensorflow:Saving checkpoints for 67004 into /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.          0.00000002  0.00000285  0.99995327  0.          0.00000002\n",
      "   0.          0.          0.00004387  0.00000001]\n",
      " [ 0.99995196  0.          0.          0.00000002  0.          0.00001491\n",
      "   0.00003215  0.00000058  0.00000008  0.0000002 ]\n",
      " [ 0.00218761  0.00000544  0.00020506  0.00000043  0.00677388  0.00002282\n",
      "   0.9906466   0.00000022  0.00015722  0.00000076]\n",
      " [ 0.00000007  0.00000012  0.00012864  0.00004275  0.00000002  0.          0.\n",
      "   0.99975818  0.00000586  0.00006438]\n",
      " [ 0.00000002  0.00000048  0.00002953  0.99996638  0.00000002  0.00000193\n",
      "   0.00000001  0.00000006  0.00000137  0.00000007]\n",
      " [ 0.          0.00000003  0.0000001   0.00000041  0.          0.          0.\n",
      "   0.99999881  0.00000003  0.00000054]\n",
      " [ 0.00112652  0.00000223  0.00043133  0.00010349  0.00048059  0.00004573\n",
      "   0.00000242  0.16786484  0.00011844  0.82982433]\n",
      " [ 0.          0.00000035  0.00004047  0.99994802  0.00000004  0.00000662\n",
      "   0.00000001  0.00000044  0.00000265  0.00000129]\n",
      " [ 0.          0.          0.00000001  0.99996436  0.          0.00002736\n",
      "   0.          0.          0.00000565  0.00000273]\n",
      " [ 0.          0.00000006  0.0000003   0.99821508  0.00000002  0.00170167\n",
      "   0.          0.00000006  0.00004049  0.00004242]\n",
      " [ 0.          0.00000002  0.00000024  0.99955195  0.00000003  0.00008841\n",
      "   0.          0.00000001  0.00001536  0.00034396]\n",
      " [ 0.00000025  0.00000016  0.99994135  0.00000738  0.0000002   0.00000026\n",
      "   0.          0.00000532  0.00004247  0.0000026 ]\n",
      " [ 0.00002127  0.00002054  0.00000451  0.00000399  0.00000029  0.97785562\n",
      "   0.01069868  0.00000127  0.01136191  0.00003194]\n",
      " [ 0.00000009  0.00000068  0.00015588  0.00002641  0.00000024  0.00000084\n",
      "   0.00000042  0.00000009  0.99980789  0.00000751]\n",
      " [ 0.0002791   0.00299585  0.00252883  0.00095284  0.00085136  0.8958441\n",
      "   0.00990297  0.0003358   0.08472714  0.00158203]\n",
      " [ 0.00000024  0.00000005  0.00000031  0.00000715  0.00048266  0.00000815\n",
      "   0.          0.00004272  0.0000001   0.99945861]\n",
      " [ 0.00000002  0.00034233  0.99587148  0.00313324  0.00000011  0.0000002\n",
      "   0.00000002  0.00064561  0.00000678  0.00000011]\n",
      " [ 0.00000206  0.99911684  0.00001813  0.00002117  0.00023439  0.00001104\n",
      "   0.00001498  0.00000464  0.00056945  0.00000728]\n",
      " [ 0.00003765  0.02761862  0.03825795  0.0009162   0.00080686  0.00000505\n",
      "   0.00001848  0.0023595   0.92955118  0.00042866]\n",
      " [ 0.          0.          0.00000111  0.99984908  0.          0.00000141\n",
      "   0.          0.00000003  0.00014465  0.00000373]\n",
      " [ 0.          0.00000003  0.00000001  0.00000549  0.00003246  0.00000003\n",
      "   0.          0.00000236  0.00000079  0.99995887]\n",
      " [ 0.00020045  0.00007647  0.00118571  0.00000257  0.00410886  0.00037131\n",
      "   0.99403942  0.00000972  0.00000166  0.00000392]\n",
      " [ 0.          0.00000162  0.99999642  0.00000101  0.000001    0.          0.\n",
      "   0.          0.00000002  0.        ]\n",
      " [ 0.03031006  0.00004612  0.00285994  0.00026408  0.00390304  0.0001493\n",
      "   0.00083889  0.04056416  0.00310061  0.91796386]\n",
      " [ 0.00000002  0.00000004  0.          0.00029169  0.00000008  0.99945515\n",
      "   0.00001969  0.          0.00013529  0.00009817]\n",
      " [ 0.00000853  0.00000004  0.00000324  0.00000016  0.00000065  0.0000136\n",
      "   0.99997258  0.          0.00000122  0.        ]\n",
      " [ 0.00000005  0.0000004   0.00003297  0.10769612  0.00007403  0.00002923\n",
      "   0.00000001  0.03465434  0.00070047  0.85681242]\n",
      " [ 0.00000012  0.0000002   0.0000003   0.00000002  0.00000566  0.00001379\n",
      "   0.99997997  0.          0.          0.        ]\n",
      " [ 0.          0.00000081  0.9999851   0.0000138   0.          0.          0.\n",
      "   0.          0.0000002   0.        ]\n",
      " [ 0.00000001  0.          0.00000325  0.00000481  0.00000098  0.          0.\n",
      "   0.99995172  0.00000028  0.00003899]\n",
      " [ 0.          0.00000003  0.          0.0000067   0.00006393  0.00000013\n",
      "   0.          0.00000939  0.00000043  0.99991941]\n",
      " [ 0.00000006  0.00000004  0.00000192  0.00000458  0.0000019   0.00000033\n",
      "   0.          0.99985349  0.00003831  0.00009944]\n",
      " [ 0.00004356  0.00032896  0.00264171  0.00004112  0.00001984  0.91392076\n",
      "   0.05733     0.00000015  0.02557917  0.00009478]\n",
      " [ 0.00000014  0.00000616  0.00000436  0.00032314  0.00003305  0.00012558\n",
      "   0.          0.00036978  0.00005952  0.99907827]\n",
      " [ 0.00000003  0.00000085  0.00001539  0.00000788  0.00000004  0.00000001\n",
      "   0.          0.99996364  0.00000262  0.0000095 ]\n",
      " [ 0.00000144  0.0000004   0.00003635  0.00000225  0.99981183  0.00000177\n",
      "   0.00000432  0.00013139  0.00000218  0.00000817]\n",
      " [ 0.0000006   0.99990392  0.00000809  0.00000153  0.00002132  0.00000085\n",
      "   0.00000182  0.00002711  0.00003429  0.00000053]\n",
      " [ 0.99978691  0.00000007  0.00000526  0.00000028  0.          0.0001541\n",
      "   0.0000002   0.00000836  0.00000338  0.00004146]\n",
      " [ 0.00000031  0.00000026  0.00000033  0.00007478  0.00002691  0.05916731\n",
      "   0.00000017  0.00005744  0.0000206   0.94065183]\n",
      " [ 0.          0.          0.99999666  0.00000263  0.          0.          0.\n",
      "   0.          0.00000072  0.        ]\n",
      " [ 0.00056618  0.00014635  0.01054833  0.00608715  0.00000086  0.00000244\n",
      "   0.          0.9727509   0.00118581  0.00871189]\n",
      " [ 0.99991667  0.00000227  0.00003229  0.00000002  0.00000008  0.00000025\n",
      "   0.00004783  0.00000027  0.00000021  0.00000008]\n",
      " [ 0.00000278  0.00000004  0.00000012  0.          0.00028176  0.00000046\n",
      "   0.99971479  0.          0.          0.        ]\n",
      " [ 0.99816728  0.00000068  0.00003376  0.0000245   0.00000008  0.00024331\n",
      "   0.00000168  0.00122942  0.00013158  0.00016754]\n",
      " [ 0.0000001   0.00000061  0.00000045  0.00000022  0.00002351  0.0005242\n",
      "   0.99945074  0.          0.00000012  0.        ]\n",
      " [ 0.          0.          0.00000446  0.00006708  0.          0.          0.\n",
      "   0.99987769  0.          0.00005074]\n",
      " [ 0.00000021  0.          0.00000003  0.00000002  0.00000035  0.00001954\n",
      "   0.99996781  0.          0.00001206  0.        ]\n",
      " [ 0.00001501  0.00000117  0.00000091  0.00096286  0.00000001  0.99881268\n",
      "   0.0000011   0.00009775  0.00010784  0.00000076]\n",
      " [ 0.00000027  0.00000017  0.00204672  0.00087807  0.00000051  0.00020405\n",
      "   0.00000134  0.00001046  0.99685448  0.0000039 ]\n",
      " [ 0.          0.          0.00000004  0.99996686  0.          0.00003005\n",
      "   0.          0.          0.00000304  0.00000007]\n",
      " [ 0.00000156  0.9992705   0.00000485  0.00000262  0.0001544   0.00000125\n",
      "   0.0000492   0.00028634  0.00016269  0.0000666 ]\n",
      " [ 0.00006955  0.00005244  0.00016399  0.00024206  0.00000469  0.99452579\n",
      "   0.00112325  0.00003854  0.00377519  0.0000046 ]\n",
      " [ 0.00000259  0.00000002  0.00000179  0.00000138  0.00000181  0.02772265\n",
      "   0.00008476  0.00000016  0.97218072  0.00000422]\n",
      " [ 0.00009822  0.99787998  0.00034785  0.0000726   0.0000997   0.00005259\n",
      "   0.00012731  0.0005734   0.0007462   0.00000229]\n",
      " [ 0.00000011  0.0000001   0.00000001  0.00115442  0.          0.99879253\n",
      "   0.00000427  0.          0.00002923  0.00001934]\n",
      " [ 0.00000153  0.0000001   0.0000021   0.00000001  0.000042    0.00023098\n",
      "   0.99972314  0.          0.00000017  0.00000002]\n",
      " [ 0.00000006  0.00000003  0.          0.99952066  0.          0.00047776\n",
      "   0.00000004  0.          0.0000008   0.00000061]\n",
      " [ 0.          0.          0.          0.00000074  0.00000002  0.99998927\n",
      "   0.00000034  0.          0.0000005   0.00000919]\n",
      " [ 0.          0.          0.          0.99999833  0.          0.00000075\n",
      "   0.          0.          0.00000099  0.00000005]\n",
      " [ 0.00000662  0.00055299  0.0000044   0.00103519  0.43768117  0.00014642\n",
      "   0.00000226  0.00334706  0.00070016  0.55652374]\n",
      " [ 0.          0.00000001  0.00000004  0.00000001  0.99998343  0.00000002\n",
      "   0.          0.00000389  0.          0.00001269]\n",
      " [ 0.00000208  0.          0.99998784  0.00000965  0.00000005  0.00000001\n",
      "   0.          0.00000004  0.00000041  0.00000003]\n",
      " [ 0.00000981  0.00002188  0.00073376  0.00003985  0.98624843  0.00004347\n",
      "   0.00000677  0.00007813  0.00005843  0.01275933]\n",
      " [ 0.02870542  0.00002184  0.01514562  0.0000995   0.0006768   0.00040625\n",
      "   0.00008966  0.77378553  0.00152306  0.1795463 ]\n",
      " [ 0.00026818  0.14547256  0.82448679  0.00074892  0.0011897   0.00001151\n",
      "   0.02779737  0.          0.00002495  0.        ]\n",
      " [ 0.00033815  0.1921384   0.01931377  0.26589981  0.00054638  0.00077517\n",
      "   0.00000162  0.42584106  0.03804481  0.05710083]\n",
      " [ 0.0009124   0.00000797  0.9826051   0.00007972  0.00003282  0.00001955\n",
      "   0.00004145  0.00101417  0.01488949  0.00039732]\n",
      " [ 0.0000035   0.00000125  0.00003312  0.99862468  0.00000003  0.00124207\n",
      "   0.00000499  0.00000002  0.00009019  0.00000015]\n",
      " [ 0.00000073  0.00003255  0.00063115  0.00013471  0.00000672  0.00000025\n",
      "   0.          0.99760383  0.00158264  0.00000744]\n",
      " [ 0.00000003  0.          0.          0.00000479  0.          0.99935192\n",
      "   0.00000306  0.          0.0006312   0.00000904]\n",
      " [ 0.00000022  0.00000044  0.00001844  0.00001084  0.00016523  0.00000364\n",
      "   0.00002827  0.00000035  0.99962211  0.00015033]\n",
      " [ 0.00000088  0.00000356  0.00000036  0.00000004  0.00000018  0.00017171\n",
      "   0.99977976  0.          0.00004347  0.00000003]\n",
      " [ 0.00001182  0.00006572  0.00028977  0.00101461  0.00005505  0.0008487\n",
      "   0.00003603  0.00000585  0.99715853  0.00051393]\n",
      " [ 0.00000482  0.00071095  0.00000266  0.84750801  0.00002611  0.06701553\n",
      "   0.00000006  0.00001573  0.00032366  0.08439233]\n",
      " [ 0.          0.          0.          0.00000121  0.          0.99999642\n",
      "   0.          0.          0.00000003  0.00000238]\n",
      " [ 0.00000067  0.99990213  0.00000281  0.00000025  0.00000165  0.00000006\n",
      "   0.00000077  0.00008795  0.00000174  0.00000176]\n",
      " [ 0.          0.00000004  0.00000002  0.          0.00000022  0.00000008\n",
      "   0.          0.99995518  0.00000001  0.00004452]\n",
      " [ 0.00000071  0.00000001  0.00001819  0.0004269   0.00000059  0.00000025\n",
      "   0.          0.00002751  0.99936169  0.00016416]\n",
      " [ 0.00000001  0.00001146  0.99998796  0.00000014  0.          0.\n",
      "   0.00000001  0.          0.00000046  0.        ]\n",
      " [ 0.          0.          0.          0.          0.99998224  0.\n",
      "   0.00000015  0.00000004  0.00000003  0.00001766]\n",
      " [ 0.00089531  0.00001139  0.00001218  0.00000046  0.00000154  0.0009733\n",
      "   0.99810565  0.          0.00000014  0.        ]\n",
      " [ 0.9996891   0.00000015  0.00028022  0.00000188  0.00000064  0.00000103\n",
      "   0.00000104  0.00002383  0.00000126  0.00000088]\n",
      " [ 0.00000424  0.00052829  0.00001051  0.00004073  0.91176122  0.00216457\n",
      "   0.00003306  0.00014413  0.00112268  0.08419062]\n",
      " [ 0.          0.00000032  0.00000619  0.0000004   0.00000001  0.00000229\n",
      "   0.00000001  0.          0.99999082  0.00000001]\n",
      " [ 0.00000001  0.0000018   0.00000734  0.00003318  0.00000002  0.00000004\n",
      "   0.          0.99994469  0.          0.00001282]\n",
      " [ 0.00000322  0.00000114  0.00000328  0.0000022   0.970532    0.00000502\n",
      "   0.00002408  0.0002656   0.00053843  0.02862504]\n",
      " [ 0.00000108  0.00000291  0.00158932  0.00183141  0.00000018  0.00008081\n",
      "   0.00000042  0.00000039  0.99634808  0.00014536]\n",
      " [ 0.98468637  0.00022151  0.01179583  0.0000661   0.00002663  0.00010962\n",
      "   0.00039311  0.0000277   0.00232278  0.00035042]\n",
      " [ 0.          0.00000011  0.00000406  0.99996042  0.          0.00001237\n",
      "   0.          0.          0.00000946  0.00001362]\n",
      " [ 0.00000009  0.          0.00000078  0.00000004  0.00000395  0.00062385\n",
      "   0.99936575  0.          0.00000555  0.00000002]\n",
      " [ 0.00000017  0.          0.00000023  0.0000155   0.00003443  0.00014964\n",
      "   0.          0.00005498  0.00000687  0.99973816]\n",
      " [ 0.0009915   0.00000126  0.00001177  0.00000258  0.00011313  0.00047749\n",
      "   0.99840194  0.          0.00000034  0.00000003]\n",
      " [ 0.00005501  0.00000535  0.00022323  0.03374586  0.0000151   0.00016213\n",
      "   0.00000051  0.00000034  0.01215213  0.9536404 ]\n",
      " [ 0.00000524  0.00000798  0.00000115  0.00045854  0.00045743  0.01152089\n",
      "   0.00000065  0.00138397  0.00100193  0.9851622 ]\n",
      " [ 0.00000078  0.99732482  0.00000231  0.00000157  0.00124116  0.\n",
      "   0.00000002  0.00141524  0.00000678  0.00000742]\n",
      " [ 0.0002117   0.00000056  0.00000045  0.00000041  0.00000001  0.00004552\n",
      "   0.99928683  0.          0.00045396  0.00000064]\n",
      " [ 0.00000005  0.00006409  0.99955815  0.00034514  0.          0.00000012\n",
      "   0.          0.00002735  0.00000504  0.        ]\n",
      " [ 0.00033276  0.00000495  0.98045051  0.00030619  0.00058371  0.00005094\n",
      "   0.00012303  0.0003768   0.01775445  0.00001663]\n",
      " [ 0.00000169  0.00003388  0.00065963  0.00219733  0.00000063  0.00000067\n",
      "   0.          0.9968971   0.00002768  0.0001813 ]\n",
      " [ 0.00000173  0.9995172   0.00013005  0.00004486  0.00012555  0.00000154\n",
      "   0.00000854  0.00001264  0.00015152  0.00000628]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0830458, step = 67004\n",
      "INFO:tensorflow:global_step/sec: 184.219\n",
      "INFO:tensorflow:loss = 0.00364095, step = 67104 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.85\n",
      "INFO:tensorflow:loss = 0.0128426, step = 67204 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.945\n",
      "INFO:tensorflow:loss = 0.0529519, step = 67304 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.951\n",
      "INFO:tensorflow:loss = 0.0475676, step = 67404 (0.464 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 67503 into /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.051531.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1b894f1fb38>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-04-14:34:12\n",
      "INFO:tensorflow:Restoring parameters from /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt-67503\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-04-14:34:12\n",
      "INFO:tensorflow:Saving dict for global step 67503: accuracy = 0.9842, global_step = 67503, loss = 0.0469145\n",
      "evaluate: {'accuracy': 0.9842, 'loss': 0.046914466, 'global_step': 67503}\n",
      "INFO:tensorflow:Restoring parameters from /home/w/tmp/tensorflow/mnist_convnet_model\\model.ckpt-67503\n",
      "预测结果： 7  真实结果： 7\n",
      "预测结果： 2  真实结果： 2\n",
      "预测结果： 1  真实结果： 1\n",
      "预测结果： 0  真实结果： 0\n",
      "预测结果： 4  真实结果： 4\n",
      "预测结果： 1  真实结果： 1\n",
      "预测结果： 4  真实结果： 4\n",
      "预测结果： 9  真实结果： 9\n",
      "预测结果： 5  真实结果： 5\n",
      "预测结果： 9  真实结果： 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 限制显卡内存\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    def conv_layer(inputs, filters, kernel_size=[5, 5], padding='same', activation=tf.nn.relu):\n",
    "        return tf.layers.conv2d(\n",
    "            inputs=inputs,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            activation=activation)\n",
    "\n",
    "    def pool_layer(inputs,\n",
    "                   pool_size=[2, 2],\n",
    "                   strides=2):\n",
    "        return tf.layers.max_pooling2d(\n",
    "            inputs=inputs,\n",
    "            pool_size=pool_size,\n",
    "            strides=strides)\n",
    "\n",
    "    # input\n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "\n",
    "    # conv 1\n",
    "    conv1 = conv_layer(input_layer, 32)\n",
    "\n",
    "    # pooling layer 1\n",
    "    pool1 = pool_layer(conv1)\n",
    "\n",
    "    # conv 2\n",
    "    conv2 = conv_layer(pool1, 64)\n",
    "\n",
    "    # pooling layer 2\n",
    "    pool2 = pool_layer(conv2)\n",
    "\n",
    "    # func 1\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # drop out\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # output\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    # 以上是普通cnn结构，但用estimator，还需要定义 loss，optimizer,prediction\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # loss(both train,eval) @这个定义还必须在 predict 之后！否则会出错，感觉很诡异啊！！！\n",
    "    loss = tf.losses.softmax_cross_entropy(logits=logits,\n",
    "                                           onehot_labels=tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10))\n",
    "    #\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:  # optimizer(only for train)\n",
    "        op = tf.train.GradientDescentOptimizer(0.001).minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=op)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        metric_op = {'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=metric_op)\n",
    "\n",
    "\n",
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "# Create the Estimator\n",
    "classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/home/w/tmp/tensorflow/mnist_convnet_model\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors={\"probabilities\": \"softmax_tensor\"}, every_n_iter=500)\n",
    "\n",
    "#  train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "classifier.train(input_fn=train_input_fn,\n",
    "                 steps=500,\n",
    "                 hooks=[logging_hook])\n",
    "\n",
    "# evaluate model\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_v = classifier.evaluate(input_fn=eval_input_fn)\n",
    "print('evaluate:', eval_v)\n",
    "\n",
    "# prediction test data\n",
    "prediction_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': eval_data[0:10]},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "predic_result = classifier.predict(input_fn=prediction_input_fn)\n",
    "predic_class = [x['classes'] for x in predic_result]\n",
    "\n",
    "for i in range(10):\n",
    "    print('预测结果：', predic_class[i], ' 真实结果：', eval_labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.metrics.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tf.estimator.EstimatorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tf.estimator.Estimator.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.estimator.inputs.numpy_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
